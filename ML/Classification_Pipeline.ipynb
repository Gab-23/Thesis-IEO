{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the python kernel we are using, should be the local one, not the one in the virtual environment. <br>\n",
    "NOTE: A proper virtual environment will be setup later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up main variables that will be called later on, for readibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_bool = True\n",
    "path_to_datasets = \"/home/ieo7429/Desktop/THESIS_GAB/outfiles/target_variables/ML_tables_regression_classification_BRCA_v2.RData\"\n",
    "mode = \"regrout\"\n",
    "cols_to_drop = [\"ampl_score\",\"del_score\",\"mean_log2FC\",\"weighted_log2FC\", \"joint_probability\", \"bool_diff_acc\", \n",
    "                \"sign_mean_log2FC_2\", \"sign_mean_log2FC_3\", \n",
    "                \"weighted_coef_of_var_log2FC\", \"weighted_log2FC\", \"bin\", \"Type\"]\n",
    "\n",
    "if \"ampl_score\" in cols_to_drop and \"del_score\" in cols_to_drop:\n",
    "    condition = \"without_CNA\"\n",
    "else:\n",
    "    condition = \"with CNA\"\n",
    "\n",
    "n_jobs = 60\n",
    "nthread = 60\n",
    "n_iter_bsearch = 50\n",
    "n_iter_rsearch = 100\n",
    "\n",
    "split_random_state = 489574\n",
    "regressor_seed = 3737\n",
    "regressor_random_state = 39473209\n",
    "hypertune_random_state_bsearch = 3847\n",
    "hypertune_random_state_rsearch = 49574\n",
    "kfold_random_state = 4909\n",
    "\n",
    "outer_cv = 5\n",
    "inner_cv = 3\n",
    "plot_variation = False\n",
    "plot_gain = False\n",
    "plot_shap = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "if install_bool:\n",
    "    ! pip install pickleshare\n",
    "    ! pip install pandas\n",
    "    ! pip install scikit-learn\n",
    "    ! pip install seaborn\n",
    "    ! pip install scipy\n",
    "    ! pip install --upgrade pip setuptools wheel\n",
    "    ! pip install rpy2\n",
    "    ! pip install shap\n",
    "    ! pip install \"numpy<=2.1\"\n",
    "    %pip install -U ipywidgets\n",
    "\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import rpy2.robjects as ro\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import warnings\n",
    "import pickleshare\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_datasets_from_r\n",
    "Reads \"ML.Tables\" .Rdata file and converts it to a nested dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets_from_r(file_path):\n",
    "\n",
    "    \"\"\" \n",
    "    The function uses rpy2 to load datasets from an RData file.\n",
    "    In particular it expects a list of data.frames\n",
    "    It returns a dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    \n",
    "    pandas2ri.activate()\n",
    "\n",
    "    ro.r['load'](file_path) # load the .RData\n",
    "\n",
    "    env = ro.globalenv # set the environment\n",
    "\n",
    "    r_list = env[list(env.keys())[0]] # take the list object\n",
    "\n",
    "    list_names = ro.r['names'](r_list) # take the names\n",
    "    list_names = [str(name) for name in list_names]\n",
    "\n",
    "    df_dict = {} # initialize outer dictionary\n",
    "    with (ro.default_converter + ro.pandas2ri.converter).context(): # start the conversion\n",
    "    # the conversion transforms a list of lists of lists of data.frames \n",
    "    # to a list of dictionaries of dictionaries of dictionaries of DataFrame\n",
    "        i = 0\n",
    "        for outer_dict in r_list:\n",
    "            df_dict[list_names[i]] = outer_dict\n",
    "            i += 1\n",
    "            \n",
    "    return(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gini_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the gini coefficient (2 * AUC - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient_score(y_true, y_pred_prob, **kwargs):\n",
    "    y_score = y_pred_prob\n",
    "    auc_score = sk.metrics.roc_auc_score(y_true, y_score)\n",
    "    gini_coef = 2 * auc_score - 1\n",
    "    return gini_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_coefficient = sk.metrics.make_scorer(gini_coefficient_score, response_method = \"predict_proba\", greater_is_better= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_selector\n",
    "his function performs Incremental Feature Selection (IFS) to produce a reduced model <br> with best gini coefficient (2 * AUC - 1) performance with cross validation.\n",
    "Mean absolute SHAP values are used to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selector_shap(feature_names, feature_importances, model, \n",
    "                          X_train, X_test, y_train, inner_cv,\n",
    "                          plot = True, verbose = True):\n",
    "\n",
    "    \"\"\"\n",
    "    The function takes as input feature names, feature importances, \n",
    "    a XGBoost Classifier object, the training and test dataset\n",
    "    and returns the reduced training and test datasets.\n",
    "    - plot parameter regulates whether or not to plot the Gini Coefficient vs number of feature plot\n",
    "    - verbose parameter regulates whether or not to produce a text output\n",
    "    \"\"\"\n",
    "\n",
    "    thresholds = np.sort(feature_importances) # sort the feature importances\n",
    "    num_features_list = [] # initialize list\n",
    "    gini_coef_list = [] # initialize list\n",
    "    \n",
    "    for threshold in thresholds: # iterate over thresholds\n",
    "        \n",
    "        vars_to_keep = np.where(feature_importances >= threshold)[0]\n",
    "        X_train_selected = X_train.iloc[:,vars_to_keep]\n",
    "\n",
    "        gini_coef_scores = sk.model_selection.cross_val_score(estimator = model, \n",
    "                                                              X = X_train_selected, y = y_train, \n",
    "                                                              scoring = gini_coefficient, cv = inner_cv)\n",
    "        mean_gini_coef_score = np.mean(gini_coef_scores)\n",
    "        \n",
    "        num_features_list.append(X_train_selected.shape[1]) # append\n",
    "        gini_coef_list.append(mean_gini_coef_score) # append\n",
    "\n",
    "        if verbose:\n",
    "            print(f'> threshold={threshold}, features={X_train_selected.shape[1]}, gini coefficient={mean_gini_coef_score}')\n",
    "        \n",
    "        if len(vars_to_keep) == 1:\n",
    "            break\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(num_features_list, gini_coef_list, marker='o')\n",
    "        plt.xlabel('Number of Selected Features')\n",
    "        plt.ylabel('cross validated mean Ginny coefficient')\n",
    "        plt.title('Gini coefficient vs. Number of Selected Features')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    optimal_threshold_index = np.argmax(gini_coef_list)\n",
    "    optimal_num_features = num_features_list[optimal_threshold_index]\n",
    "    \n",
    "    if (optimal_threshold_index) == 0:\n",
    "        optimal_threshold = 0\n",
    "    else:   \n",
    "        optimal_threshold = thresholds[optimal_threshold_index - 1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "        print(f\"Number of Selected Features: {optimal_num_features}\")\n",
    "        print(f\"Gini coef at Optimal Threshold: {gini_coef_list[optimal_threshold_index]:.4f}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    n = 5\n",
    "    selected_features = feature_names[np.where(feature_importances > optimal_threshold)]\n",
    "    selected_features = [str(name) for name in selected_features]\n",
    "    discarded_features = [str(name) for name in feature_names if str(name) not in selected_features]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Selected features are: \\n\")\n",
    "        for i in range(0,len(selected_features), n):\n",
    "            print(\"  \".join(selected_features[i:i+n]))\n",
    "        print(\"\\n\")\n",
    "        print(\"Discarded features are: \\n\")\n",
    "        for i in range(0,len(discarded_features), n):\n",
    "            print(\"  \".join(discarded_features[i:i+n]))\n",
    "\n",
    "    X_train_reduced = X_train[selected_features]\n",
    "    X_test_reduced = X_test[selected_features]\n",
    "    \n",
    "    return(X_train_reduced, X_test_reduced, selected_features)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function performs nested cross validation, optimizing the model at each step in order to properly estimate the model's error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_CV(outer_cv, inner_cv,\n",
    "               X_train, y_train, \n",
    "               model, search_space, \n",
    "               n_jobs, n_iter_bsearch, verbose):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function performs nested cross validation to estimate model's error rate\n",
    "    It take the cv number, the training dataset, the target variable, the model or a BayesSearchCV\n",
    "    and a search space to perform hyperparameter tuning\n",
    "    \"\"\"\n",
    "\n",
    "    kf = sk.model_selection.KFold(n_splits = outer_cv, \n",
    "                                  shuffle = True, \n",
    "                                  random_state = kfold_random_state)\n",
    "    \n",
    "    accuracy_array = np.zeros(outer_cv)\n",
    "    f1_array = np.zeros(outer_cv)\n",
    "    precision_array = np.zeros(outer_cv)\n",
    "    recall_array = np.zeros(outer_cv)\n",
    "    roc_auc_array = np.zeros(outer_cv)\n",
    "    predictions_array = np.zeros(len(X_train))\n",
    "    probas_array = np.zeros(len(X_train))\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold #{i + 1}\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 1 (Splitting)\")\n",
    "        \n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 2 (Tuning)\")\n",
    "\n",
    "        opti = BayesSearchCV(\n",
    "            estimator = model,\n",
    "            search_spaces = search_space,\n",
    "            n_iter = n_iter_bsearch,\n",
    "            cv = inner_cv,\n",
    "            random_state = hypertune_random_state_bsearch,\n",
    "            refit = True,\n",
    "            n_jobs = n_jobs,\n",
    "            verbose = False\n",
    "        )\n",
    "\n",
    "        opti.fit(X_train_cv, y_train_cv)\n",
    "        best_model = opti.best_estimator_\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"STEP 3 (Prediction)\")\n",
    "\n",
    "        cv_predictions = best_model.predict(X_val)\n",
    "        cv_pred_probas = best_model.predict_proba(X_val)[:,1]\n",
    "        \n",
    "        cv_accuracy = sk.metrics.accuracy_score(y_val, cv_predictions)\n",
    "        cv_f1 = sk.metrics.f1_score(y_val, cv_predictions)\n",
    "        cv_precision = sk.metrics.precision_score(y_val, cv_predictions)\n",
    "        cv_recall = sk.metrics.recall_score(y_val, cv_predictions)\n",
    "        cv_roc_auc = sk.metrics.roc_auc_score(y_val, cv_pred_probas)\n",
    "                \n",
    "        accuracy_array[i] = cv_accuracy \n",
    "        f1_array[i] = cv_f1\n",
    "        precision_array[i] = cv_precision\n",
    "        recall_array[i] = cv_recall\n",
    "        roc_auc_array[i] = cv_roc_auc\n",
    "        predictions_array[val_index] = cv_predictions\n",
    "        probas_array[val_index] = cv_pred_probas\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(accuracy_array, f1_array, precision_array, recall_array, roc_auc_array, predictions_array, probas_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV la vendetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_CV_revenge(outer_cv, inner_cv,\n",
    "                      X_train, y_train, \n",
    "                      model, search_space, \n",
    "                      n_jobs, n_iter_bsearch, verbose):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function performs nested cross validation to estimate model's error rate\n",
    "    It take the cv number, the training dataset, the target variable, the model or a BayesSearchCV\n",
    "    and a search space to perform hyperparameter tuning\n",
    "    \"\"\"\n",
    "    \n",
    "    kf = sk.model_selection.KFold(n_splits = outer_cv, \n",
    "                                  shuffle=True, \n",
    "                                  random_state = kfold_random_state)\n",
    "    \n",
    "\n",
    "    hyperparam_list = []\n",
    "    selected_features_list = []\n",
    "    accuracy_array = np.zeros(outer_cv)\n",
    "    f1_array = np.zeros(outer_cv)\n",
    "    precision_array = np.zeros(outer_cv)\n",
    "    recall_array = np.zeros(outer_cv)\n",
    "    roc_auc_array = np.zeros(outer_cv)\n",
    "    predictions_array = np.zeros(len(X_train))\n",
    "    probas_array = np.zeros(len(X_train))\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold #{i + 1}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"STEP 1 (Splitting)\")\n",
    "            \n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 2 (Tuning)\")\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.1 (HyperParameter Tuning Part 1)\")\n",
    "        \n",
    "        opti = BayesSearchCV(\n",
    "            estimator = model,\n",
    "            search_spaces = search_space,\n",
    "            n_iter = n_iter_bsearch,\n",
    "            cv = inner_cv,\n",
    "            random_state = hypertune_random_state_bsearch,\n",
    "            refit = True,\n",
    "            n_jobs = n_jobs,\n",
    "            verbose = 0\n",
    "        )\n",
    "        \n",
    "        opti.fit(X_train_cv, y_train_cv)\n",
    "        best_model = opti.best_estimator_\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.2 (SHAP)\")\n",
    "        \n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "        feature_names = best_model.feature_names_in_\n",
    "        feature_importances_shap = np.mean(np.abs(explainer.shap_values(X_train_cv)), axis = 0)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"STEP 2.3 (Feature selection)\")\n",
    "        \n",
    "        X_train_cv_reduced, X_val_cv_reduced, selected_features = feature_selector_shap(feature_names, feature_importances_shap, \n",
    "                                                                                        best_model, \n",
    "                                                                                        X_train_cv, X_val, y_train_cv,\n",
    "                                                                                        inner_cv,\n",
    "                                                                                        plot = False, verbose = False)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.4 (HyperParameter Tuning Part 2)\")\n",
    "        \n",
    "        opti_fs = BayesSearchCV(\n",
    "            estimator = best_model, \n",
    "            search_spaces = search_space, \n",
    "            n_iter = n_iter_bsearch, \n",
    "            cv = inner_cv,\n",
    "            random_state = hypertune_random_state_bsearch,\n",
    "            refit = True, \n",
    "            n_jobs = n_jobs,\n",
    "            verbose = 0\n",
    "        )\n",
    "        \n",
    "        opti_fs.fit(X_train_cv_reduced, y_train_cv)\n",
    "        best_model_fs = opti_fs.best_estimator_\n",
    "        best_params_fs = opti_fs.best_params_\n",
    "\n",
    "        if verbose: \n",
    "            print(\"STEP 3 (Threshold Tuning)\")\n",
    "\n",
    "        tuner_thr = sk.model_selection.TunedThresholdClassifierCV(best_model_fs, \n",
    "                                                                  scoring = \"balanced_accuracy\", \n",
    "                                                                  cv = inner_cv)\n",
    "        \n",
    "        model_thr = tuner_thr.fit(X_train_cv_reduced, y_train_cv)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 4 (Prediction)\")\n",
    "        \n",
    "        cv_predictions = model_thr.predict(X_val_cv_reduced)\n",
    "        cv_pred_probas = model_thr.predict_proba(X_val_cv_reduced)[:,1]\n",
    "        \n",
    "        cv_accuracy = sk.metrics.accuracy_score(y_val, cv_predictions)\n",
    "        cv_f1 = sk.metrics.f1_score(y_val, cv_predictions)\n",
    "        cv_precision = sk.metrics.precision_score(y_val, cv_predictions)\n",
    "        cv_recall = sk.metrics.recall_score(y_val, cv_predictions)\n",
    "        cv_roc_auc = sk.metrics.roc_auc_score(y_val, cv_pred_probas)\n",
    "        \n",
    "        hyperparam_list.append(best_params_fs)\n",
    "        selected_features_list.append(selected_features)\n",
    "        accuracy_array[i] = cv_accuracy \n",
    "        f1_array[i] = cv_f1\n",
    "        precision_array[i] = cv_precision\n",
    "        recall_array[i] = cv_recall\n",
    "        roc_auc_array[i] = cv_roc_auc\n",
    "        predictions_array[val_index] = cv_predictions\n",
    "        probas_array[val_index] = cv_pred_probas\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(hyperparam_list, selected_features_list, \n",
    "           accuracy_array, f1_array, precision_array, \n",
    "           recall_array, roc_auc_array, predictions_array, probas_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = load_datasets_from_r(path_to_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = output_dict[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 5))\n",
    "\n",
    "A = axes[0,0]\n",
    "B = axes[0,1]\n",
    "C = axes[1,0]\n",
    "D = axes[1,1]\n",
    "\n",
    "sns.barplot(working_df.bool_diff_acc.value_counts(), ax = A)\n",
    "sns.barplot(working_df.sign_mean_log2FC_1.value_counts(), ax = B)\n",
    "sns.barplot(working_df.sign_mean_log2FC_2.value_counts(), ax = C)\n",
    "sns.barplot(working_df.sign_mean_log2FC_3.value_counts(), ax = D)\n",
    "\n",
    "A.set_title(\"Differential Accessibility across patients (boolean) [A]\")\n",
    "B.set_title(\"Differential Accessibility direction (v = 1) [B]\")\n",
    "C.set_title(\"Differential Accessibility direction (v = 2) [C]\")\n",
    "D.set_title(\"Differential Accessibility direction (v = 3) [D]\")\n",
    "\n",
    "A.set_xlabel(\"\"); A.set_ylabel(\"\")\n",
    "B.set_xlabel(\"\"); B.set_ylabel(\"\")\n",
    "C.set_xlabel(\"\"); C.set_ylabel(\"\")\n",
    "D.set_xlabel(\"\"); D.set_ylabel(\"\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ids = working_df[[\"bin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.drop(cols_to_drop, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df.iloc[:, 1:]\n",
    "y = working_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"sign_mean_log2FC_1\" in X.columns:\n",
    "    raise Exception(\"Target Variable in the training set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, bin_train, bin_test = sk.model_selection.train_test_split(X, y, bin_ids, test_size=0.3, random_state=123)\n",
    "y_train = np.where(y_train == 1, 1, 0); y_test = np.where(y_test == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Classifier and the Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(n_jobs = 40, nthread = 40, seed = 0, random_state = 42)\n",
    "\n",
    "search_space_bayes = {  \n",
    "    'learning_rate': (0.001, 1.0, 'log-uniform'),  \n",
    "    'n_estimators': (50, 500),  \n",
    "    'max_depth': (3, 15),  \n",
    "    'min_child_weight': (1, 10),  \n",
    "    'gamma': (1e-9, 5.0, 'log-uniform'),  \n",
    "    'subsample': (0.5, 1.0, 'uniform'),  \n",
    "    'colsample_bytree': (0.5, 1.0, 'uniform'),  \n",
    "    'colsample_bylevel': (0.5, 1.0, 'uniform'),  \n",
    "    'reg_alpha': (1e-9, 10.0, 'log-uniform'),  \n",
    "    'reg_lambda': (1e-9, 10.0, 'log-uniform'),  \n",
    "    'scale_pos_weight': (1e-6, 100, 'log-uniform'),  \n",
    "    'max_delta_step': (0, 10),  \n",
    "    'objective': ['binary:logistic'],  \n",
    "    'booster': ['gbtree', 'dart'],  \n",
    "    'eval_metric': ['logloss', 'error', 'auc']  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NESTED CV PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "STEP 3 (Threshold Tuning)\n",
      "STEP 4 (Prediction)\n",
      "Fold #2\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "STEP 3 (Threshold Tuning)\n",
      "STEP 4 (Prediction)\n",
      "Fold #3\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "STEP 3 (Threshold Tuning)\n",
      "STEP 4 (Prediction)\n",
      "Fold #4\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "STEP 3 (Threshold Tuning)\n",
      "STEP 4 (Prediction)\n",
      "Fold #5\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "STEP 3 (Threshold Tuning)\n",
      "STEP 4 (Prediction)\n"
     ]
    }
   ],
   "source": [
    "results = nested_CV_revenge(\n",
    "    outer_cv, inner_cv,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=classifier,\n",
    "    search_space=search_space_bayes,\n",
    "    n_jobs= n_jobs, n_iter_bsearch = n_iter_bsearch,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "(\n",
    "    hyperparam_list,\n",
    "    selected_features_list,\n",
    "    accuracy_array,\n",
    "    f1_array,\n",
    "    precision_array,\n",
    "    recall_array,\n",
    "    roc_auc_array,\n",
    "    predictions_array,\n",
    "    probas_array\n",
    ") = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cross-validated accuracy (cv = {outer_cv}) is: {np.mean(accuracy_array)}\")\n",
    "print(f\"The cross-validated f1 (cv = {outer_cv}) is: {np.mean(f1_array)}\")\n",
    "print(f\"The cross-validated precision (cv = {outer_cv}) is: {np.mean(precision_array)}\")\n",
    "print(f\"The cross-validated R recall (cv = {outer_cv}) is: {np.mean(recall_array)}\")\n",
    "print(f\"The cross-validated AUC (cv = {outer_cv}) is: {np.mean(roc_auc_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_in_at_least_one_cv = set([elem for inner_list in selected_features_list for elem in inner_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_grid = {}\n",
    "\n",
    "for dictionary in hyperparam_list:\n",
    "    for k,v in dictionary.items():\n",
    "        if k in search_space_grid:\n",
    "            search_space_grid[k].update([v])\n",
    "        else:\n",
    "            search_space_grid[k] = set([v])\n",
    "\n",
    "search_space_grid = {k : list(v) for k,v in search_space_grid.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = sk.model_selection.RandomizedSearchCV(estimator = classifier, \n",
    "                                             param_distributions = search_space_grid, \n",
    "                                             cv = inner_cv, \n",
    "                                             n_jobs = n_jobs,\n",
    "                                             n_iter = n_iter_rsearch,\n",
    "                                             random_state = hypertune_random_state_rsearch, \n",
    "                                             verbose = 3, refit = True)\n",
    "opti.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = opti.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at both XGBoost native feature importance and at mean absolute SHAP values as metric of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "shap_values_numpy = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_shap:\n",
    "    print(\" / \".join([mode, condition]))\n",
    "    plt.figure(figsize = (100,25))\n",
    "    summary_plot = shap.summary_plot(shap_values, X_train, \n",
    "                                     plot_type='bar', max_display=10, plot_size= (25,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform Feature Selection using mean absolute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = model.feature_names_in_\n",
    "feature_importances_shap = np.mean(np.abs(explainer.shap_values(X_train)), axis = 0)\n",
    "\n",
    "X_train_reduced, X_test_reduced, selected_features = feature_selector_shap(feature_names, feature_importances_shap, \n",
    "                                                                            model, X_train, X_test, y_train, \n",
    "                                                                            inner_cv = inner_cv,\n",
    "                                                                            plot = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_discard = [feature for feature in selected_features if feature not in selected_features_in_at_least_one_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dropping columns never selected during Nested Cross Validation: {features_to_discard}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train_reduced.drop(features_to_discard, axis = 1)\n",
    "X_test_reduced = X_test_reduced.drop(features_to_discard, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=0.520401287016859,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.7380628505672764,\n",
       "                                           device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;logloss&#x27;,\n",
       "                                           feature_types=None,\n",
       "                                           feature_weights=None,\n",
       "                                           gamma=1.468086953174643e-06,\n",
       "                                           grow_p...\n",
       "                                        &#x27;reg_lambda&#x27;: [5.1318192154437464e-08,\n",
       "                                                       0.9285490375880117,\n",
       "                                                       0.14899683047613582,\n",
       "                                                       10.0,\n",
       "                                                       2.278661542712747e-06],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1.1075983504869995,\n",
       "                                                             2.2313295336249395,\n",
       "                                                             1.8621903738176524,\n",
       "                                                             1.5989920915204259,\n",
       "                                                             1.4682296559299814],\n",
       "                                        &#x27;subsample&#x27;: [0.872133092070879,\n",
       "                                                      0.6080517434383308,\n",
       "                                                      0.7889253179443135,\n",
       "                                                      0.8588319134818887,\n",
       "                                                      0.9955175101934302]},\n",
       "                   random_state=49574, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=0.520401287016859,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.7380628505672764,\n",
       "                                           device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=&#x27;logloss&#x27;,\n",
       "                                           feature_types=None,\n",
       "                                           feature_weights=None,\n",
       "                                           gamma=1.468086953174643e-06,\n",
       "                                           grow_p...\n",
       "                                        &#x27;reg_lambda&#x27;: [5.1318192154437464e-08,\n",
       "                                                       0.9285490375880117,\n",
       "                                                       0.14899683047613582,\n",
       "                                                       10.0,\n",
       "                                                       2.278661542712747e-06],\n",
       "                                        &#x27;scale_pos_weight&#x27;: [1.1075983504869995,\n",
       "                                                             2.2313295336249395,\n",
       "                                                             1.8621903738176524,\n",
       "                                                             1.5989920915204259,\n",
       "                                                             1.4682296559299814],\n",
       "                                        &#x27;subsample&#x27;: [0.872133092070879,\n",
       "                                                      0.6080517434383308,\n",
       "                                                      0.7889253179443135,\n",
       "                                                      0.8588319134818887,\n",
       "                                                      0.9955175101934302]},\n",
       "                   random_state=49574, verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.520401287016859, colsample_bynode=None,\n",
       "              colsample_bytree=0.9762426379753306, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=1.468086953174643e-06, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.048756201143079284, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=10,\n",
       "              max_depth=15, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=373,\n",
       "              n_jobs=40, nthread=40, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.520401287016859, colsample_bynode=None,\n",
       "              colsample_bytree=0.9762426379753306, device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;logloss&#x27;, feature_types=None, feature_weights=None,\n",
       "              gamma=1.468086953174643e-06, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.048756201143079284, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=10,\n",
       "              max_depth=15, max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=373,\n",
       "              n_jobs=40, nthread=40, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster='gbtree',\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=0.520401287016859,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=0.7380628505672764,\n",
       "                                           device=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric='logloss',\n",
       "                                           feature_types=None,\n",
       "                                           feature_weights=None,\n",
       "                                           gamma=1.468086953174643e-06,\n",
       "                                           grow_p...\n",
       "                                        'reg_lambda': [5.1318192154437464e-08,\n",
       "                                                       0.9285490375880117,\n",
       "                                                       0.14899683047613582,\n",
       "                                                       10.0,\n",
       "                                                       2.278661542712747e-06],\n",
       "                                        'scale_pos_weight': [1.1075983504869995,\n",
       "                                                             2.2313295336249395,\n",
       "                                                             1.8621903738176524,\n",
       "                                                             1.5989920915204259,\n",
       "                                                             1.4682296559299814],\n",
       "                                        'subsample': [0.872133092070879,\n",
       "                                                      0.6080517434383308,\n",
       "                                                      0.7889253179443135,\n",
       "                                                      0.8588319134818887,\n",
       "                                                      0.9955175101934302]},\n",
       "                   random_state=49574, verbose=3)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opti_fs = sk.model_selection.RandomizedSearchCV(estimator = model, \n",
    "                                                param_distributions = search_space_grid, \n",
    "                                                cv = inner_cv, \n",
    "                                                n_jobs = n_jobs,\n",
    "                                                n_iter = n_iter_rsearch,\n",
    "                                                random_state = hypertune_random_state_rsearch, \n",
    "                                                verbose = 3, refit = True)\n",
    "opti_fs.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fs = opti_fs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_fs = opti_fs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in best_params_fs.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Classification threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_thr = sk.model_selection.TunedThresholdClassifierCV(model_fs, \n",
    "                                                          scoring = \"balanced_accuracy\", \n",
    "                                                          cv = inner_cv)\n",
    "model_thr = tuner_thr.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thr = model_thr.best_threshold_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Tuned Classification Threshold is: {best_thr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array_thr = np.mean(sk.model_selection.cross_val_score(model_thr, X_train_reduced, y_train, cv = outer_cv, scoring = \"accuracy\"))\n",
    "f1_array_thr = np.mean(sk.model_selection.cross_val_score(model_thr, X_train_reduced, y_train, cv = outer_cv, scoring = \"f1\"))\n",
    "precision_array_thr = np.mean(sk.model_selection.cross_val_score(model_thr, X_train_reduced, y_train, cv = outer_cv, scoring = \"precision\"))\n",
    "recall_array_thr = np.mean(sk.model_selection.cross_val_score(model_thr, X_train_reduced, y_train, cv = outer_cv, scoring = \"recall\"))\n",
    "roc_auc_array_thr = np.mean(sk.model_selection.cross_val_score(model_thr, X_train_reduced, y_train, cv = outer_cv, scoring = \"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cross-validated accuracy (cv = {outer_cv}) is: {np.mean(accuracy_array_thr)}\")\n",
    "print(f\"The cross-validated f1 score(cv = {outer_cv}) is: {np.mean(f1_array_thr)}\")\n",
    "print(f\"The cross-validated precision (cv = {outer_cv}) is: {np.mean(precision_array_thr)}\")\n",
    "print(f\"The cross-validated recall(cv = {outer_cv}) is: {np.mean(recall_array_thr)}\")\n",
    "print(f\"The cross-validated roc auc (cv = {outer_cv}) is: {np.mean(roc_auc_array_thr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Variables for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store X_train_reduced\n",
    "%store X_test_reduced\n",
    "%store y_train\n",
    "%store y_test\n",
    "%store bin_train\n",
    "%store bin_test\n",
    "%store model_thr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
