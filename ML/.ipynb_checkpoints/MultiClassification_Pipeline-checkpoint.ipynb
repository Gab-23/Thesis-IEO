{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline - Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the python kernel we are using, should be the local one, not the one in the virtual environment. <br>\n",
    "NOTE: A proper virtual environment will be setup later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up main variables that will be called later on, for readibility purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_bool = False\n",
    "path_to_datasets = \"/home/ieo7429/Desktop/THESIS_GAB/outfiles/target_variables/ML_tables_regression_classification_BRCA_0.1Mbp_v2.RData\"\n",
    "mode = \"regrout\"\n",
    "\n",
    "cols_to_drop = [\"ampl_score\",\"del_score\",\"mean_log2FC\",\"weighted_log2FC\", \"joint_probability\", \"bool_diff_acc\", \n",
    "                \"sign_mean_log2FC_1\", \"sign_mean_log2FC_2\", \"sign_mean_log2FC_3\", \n",
    "                \"weighted_coef_of_var_log2FC\", \"weighted_log2FC\", \"bin\", \"Type\"]\n",
    "\n",
    "if \"ampl_score\" in cols_to_drop and \"del_score\" in cols_to_drop:\n",
    "    condition = \"without_CNA\"\n",
    "else:\n",
    "    condition = \"with CNA\"\n",
    "\n",
    "n_jobs = 100\n",
    "nthread = 100\n",
    "n_iter_bsearch = 25\n",
    "n_iter_rsearch = 50\n",
    "\n",
    "split_random_state = 489574\n",
    "classifier_seed = 3737\n",
    "classifier_random_state = 39473209\n",
    "hypertune_random_state_bsearch = 3847\n",
    "hypertune_random_state_rsearch = 49574\n",
    "kfold_random_state = 4909\n",
    "\n",
    "outer_cv = 3\n",
    "inner_cv = 2\n",
    "plot_gain = False\n",
    "plot_shap = True\n",
    "\n",
    "X_train_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_X_train_red\"; X_test_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_X_test_red\"\n",
    "y_train_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_y_train_red\"; y_test_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_y_test_red\"\n",
    "bin_train_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_bin_train_red\"; bin_test_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_bin_test_red\"\n",
    "model_filename = \"MultiClassification_Output_new_0.1Mbp/mclassification_final_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "if install_bool:\n",
    "    ! pip install pickleshare\n",
    "    ! pip install pandas\n",
    "    ! pip install scikit-learn\n",
    "    ! pip install seaborn\n",
    "    ! pip install scipy\n",
    "    ! pip install --upgrade pip setuptools wheel\n",
    "    ! pip install rpy2\n",
    "    ! pip install shap\n",
    "    ! pip install \"numpy<=2.1\"\n",
    "    %pip install -U ipywidgets\n",
    "\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import rpy2.robjects as ro\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "import warnings\n",
    "import pickleshare\n",
    "import pickle\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_datasets_from_r\n",
    "Reads \"ML.Tables\" .Rdata file and converts it to a nested dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets_from_r(file_path):\n",
    "\n",
    "    \"\"\" \n",
    "    The function uses rpy2 to load datasets from an RData file.\n",
    "    In particular it expects a list of data.frames\n",
    "    It returns a dictionary of pandas DataFrames.\n",
    "    \"\"\"\n",
    "    \n",
    "    pandas2ri.activate()\n",
    "\n",
    "    ro.r['load'](file_path) # load the .RData\n",
    "\n",
    "    env = ro.globalenv # set the environment\n",
    "\n",
    "    r_list = env[list(env.keys())[0]] # take the list object\n",
    "\n",
    "    list_names = ro.r['names'](r_list) # take the names\n",
    "    list_names = [str(name) for name in list_names]\n",
    "\n",
    "    df_dict = {} # initialize outer dictionary\n",
    "    with (ro.default_converter + ro.pandas2ri.converter).context(): # start the conversion\n",
    "    # the conversion transforms a list of lists of lists of data.frames \n",
    "    # to a list of dictionaries of dictionaries of dictionaries of DataFrame\n",
    "        i = 0\n",
    "        for outer_dict in r_list:\n",
    "            df_dict[list_names[i]] = outer_dict\n",
    "            i += 1\n",
    "            \n",
    "    return(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gini_coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compute the gini coefficient (2 * AUC - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_coefficient_score(y_true, y_pred_prob, **kwargs):\n",
    "    y_score = y_pred_prob\n",
    "    auc_score = sk.metrics.roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "    gini_coef = 2 * auc_score - 1\n",
    "    return gini_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_coefficient = sk.metrics.make_scorer(gini_coefficient_score, response_method = \"predict_proba\", greater_is_better= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_selector\n",
    "his function performs Incremental Feature Selection (IFS) to produce a reduced model <br> with best gini coefficient (2 * AUC - 1) performance with cross validation.\n",
    "Mean absolute SHAP values are used to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selector_shap(feature_names, feature_importances, model, \n",
    "                          X_train, X_test, y_train, inner_cv,\n",
    "                          plot = True, verbose = True):\n",
    "\n",
    "    \"\"\"\n",
    "    The function takes as input feature names, feature importances, \n",
    "    a XGBoost Classifier object, the training and test dataset\n",
    "    and returns the reduced training and test datasets.\n",
    "    - plot parameter regulates whether or not to plot the Gini Coefficient vs number of feature plot\n",
    "    - verbose parameter regulates whether or not to produce a text output\n",
    "    \"\"\"\n",
    "\n",
    "    thresholds = np.sort(feature_importances) # sort the feature importances\n",
    "    num_features_list = [] # initialize list\n",
    "    gini_coef_list = [] # initialize list\n",
    "    \n",
    "    for threshold in thresholds: # iterate over thresholds\n",
    "        \n",
    "        vars_to_keep = np.where(feature_importances >= threshold)[0]\n",
    "        X_train_selected = X_train.iloc[:,vars_to_keep]\n",
    "\n",
    "        gini_coef_scores = sk.model_selection.cross_val_score(estimator = model, \n",
    "                                                              X = X_train_selected, y = y_train, \n",
    "                                                              scoring = gini_coefficient, cv = inner_cv)\n",
    "        mean_gini_coef_score = np.mean(gini_coef_scores)\n",
    "        \n",
    "        num_features_list.append(X_train_selected.shape[1]) # append\n",
    "        gini_coef_list.append(mean_gini_coef_score) # append\n",
    "\n",
    "        if verbose:\n",
    "            print(f'> threshold={threshold}, features={X_train_selected.shape[1]}, gini coefficient={mean_gini_coef_score}')\n",
    "        \n",
    "        if len(vars_to_keep) == 1:\n",
    "            break\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(num_features_list, gini_coef_list, marker='o')\n",
    "        plt.xlabel('Number of Selected Features')\n",
    "        plt.ylabel('cross validated mean Ginny coefficient')\n",
    "        plt.title('Gini coefficient vs. Number of Selected Features')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    optimal_threshold_index = np.argmax(gini_coef_list)\n",
    "    optimal_num_features = num_features_list[optimal_threshold_index]\n",
    "    \n",
    "    if (optimal_threshold_index) == 0:\n",
    "        optimal_threshold = 0\n",
    "    else:   \n",
    "        optimal_threshold = thresholds[optimal_threshold_index - 1]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "        print(f\"Number of Selected Features: {optimal_num_features}\")\n",
    "        print(f\"Gini coef at Optimal Threshold: {gini_coef_list[optimal_threshold_index]:.4f}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    n = 5\n",
    "    selected_features = feature_names[np.where(feature_importances > optimal_threshold)]\n",
    "    selected_features = [str(name) for name in selected_features]\n",
    "    discarded_features = [str(name) for name in feature_names if str(name) not in selected_features]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Selected features are: \\n\")\n",
    "        for i in range(0,len(selected_features), n):\n",
    "            print(\"  \".join(selected_features[i:i+n]))\n",
    "        print(\"\\n\")\n",
    "        print(\"Discarded features are: \\n\")\n",
    "        for i in range(0,len(discarded_features), n):\n",
    "            print(\"  \".join(discarded_features[i:i+n]))\n",
    "\n",
    "    X_train_reduced = X_train[selected_features]\n",
    "    X_test_reduced = X_test[selected_features]\n",
    "    \n",
    "    return(X_train_reduced, X_test_reduced, selected_features)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested CV la vendetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_CV_revenge(outer_cv, inner_cv,\n",
    "                      X_train, y_train, \n",
    "                      model, search_space, \n",
    "                      n_jobs, n_iter_bsearch, verbose):\n",
    "    \n",
    "    \"\"\"\n",
    "    The function performs nested cross validation to estimate model's error rate\n",
    "    It take the cv number, the training dataset, the target variable, the model or a BayesSearchCV\n",
    "    and a search space to perform hyperparameter tuning\n",
    "    \"\"\"\n",
    "    \n",
    "    kf = sk.model_selection.KFold(n_splits = outer_cv, \n",
    "                                  shuffle=True, \n",
    "                                  random_state = kfold_random_state)\n",
    "    \n",
    "\n",
    "    hyperparam_list = []\n",
    "    selected_features_list = []\n",
    "    accuracy_array = np.zeros(outer_cv)\n",
    "    f1_array = np.zeros(outer_cv)\n",
    "    precision_array = np.zeros(outer_cv)\n",
    "    recall_array = np.zeros(outer_cv)\n",
    "    roc_auc_array = np.zeros(outer_cv)\n",
    "    predictions_array = np.zeros(len(X_train))\n",
    "    probas_array = np.zeros((len(X_train),len(np.unique(y_train))))\n",
    "    \n",
    "    i = 0\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Fold #{i + 1}\")\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"STEP 1 (Splitting)\")\n",
    "            \n",
    "        X_train_cv, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_cv, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 2 (Tuning)\")\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.1 (HyperParameter Tuning Part 1)\")\n",
    "        \n",
    "        opti = BayesSearchCV(\n",
    "            estimator = model,\n",
    "            search_spaces = search_space,\n",
    "            n_iter = n_iter_bsearch,\n",
    "            cv = inner_cv,\n",
    "            random_state = hypertune_random_state_bsearch,\n",
    "            refit = True,\n",
    "            n_jobs = n_jobs,\n",
    "            verbose = 3\n",
    "        )\n",
    "        \n",
    "        opti.fit(X_train_cv, y_train_cv)\n",
    "        best_model = opti.best_estimator_\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.2 (SHAP)\")\n",
    "        \n",
    "        explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "        feature_names = best_model.feature_names_in_\n",
    "        feature_importances_shap = np.mean(np.mean(np.abs(explainer.shap_values(X_train_cv)), axis = 0), axis = 1)\n",
    "    \n",
    "        if verbose:\n",
    "            print(\"STEP 2.3 (Feature selection)\")\n",
    "        \n",
    "        X_train_cv_reduced, X_val_cv_reduced, selected_features = feature_selector_shap(feature_names, feature_importances_shap, \n",
    "                                                                                        best_model, \n",
    "                                                                                        X_train_cv, X_val, y_train_cv,\n",
    "                                                                                        inner_cv,\n",
    "                                                                                        plot = False, verbose = False)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"STEP 2.4 (HyperParameter Tuning Part 2)\")\n",
    "        \n",
    "        opti_fs = BayesSearchCV(\n",
    "            estimator = best_model, \n",
    "            search_spaces = search_space, \n",
    "            n_iter = n_iter_bsearch, \n",
    "            cv = inner_cv,\n",
    "            random_state = hypertune_random_state_bsearch,\n",
    "            refit = True, \n",
    "            n_jobs = n_jobs,\n",
    "            verbose = 3\n",
    "        )\n",
    "        \n",
    "        opti_fs.fit(X_train_cv_reduced, y_train_cv)\n",
    "        best_model_fs = opti_fs.best_estimator_\n",
    "        best_params_fs = opti_fs.best_params_\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"STEP 3 (Prediction)\")\n",
    "        \n",
    "        cv_predictions = best_model_fs.predict(X_val_cv_reduced)\n",
    "        cv_pred_probas = best_model_fs.predict_proba(X_val_cv_reduced)\n",
    "        \n",
    "        cv_accuracy = sk.metrics.accuracy_score(y_val, cv_predictions)\n",
    "        cv_f1 = sk.metrics.f1_score(y_val, cv_predictions, average = \"macro\")\n",
    "        cv_precision = sk.metrics.precision_score(y_val, cv_predictions, average = \"macro\")\n",
    "        cv_recall = sk.metrics.recall_score(y_val, cv_predictions, average = \"macro\")\n",
    "        cv_roc_auc = sk.metrics.roc_auc_score(y_val, cv_pred_probas, multi_class='ovr', average = \"macro\")\n",
    "        \n",
    "        hyperparam_list.append(best_params_fs)\n",
    "        selected_features_list.append(selected_features)\n",
    "        accuracy_array[i] = cv_accuracy \n",
    "        f1_array[i] = cv_f1\n",
    "        precision_array[i] = cv_precision\n",
    "        recall_array[i] = cv_recall\n",
    "        roc_auc_array[i] = cv_roc_auc\n",
    "        predictions_array[val_index] = cv_predictions\n",
    "        probas_array[val_index] = cv_pred_probas\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "    return(hyperparam_list, selected_features_list, \n",
    "           accuracy_array, f1_array, precision_array, \n",
    "           recall_array, roc_auc_array, predictions_array, probas_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = load_datasets_from_r(path_to_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = output_dict[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_dir_1 = np.where(\n",
    "    (working_df.bool_diff_acc == 1) & (working_df.sign_mean_log2FC_1 == 1), 2,\n",
    "    np.where(\n",
    "        (working_df.bool_diff_acc == 1) & (working_df.sign_mean_log2FC_1 == -1), 0, 1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"significant_dir_1\"] = significant_dir_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 5))\n",
    "\n",
    "A = axes[0,0]\n",
    "B = axes[0,1]\n",
    "C = axes[1,0]\n",
    "D = axes[1,1]\n",
    "E = axes[2,0]\n",
    "F = axes[2,1]\n",
    "\n",
    "sns.barplot(working_df.bool_diff_acc.value_counts(), ax = A)\n",
    "sns.barplot(working_df.sign_mean_log2FC_1.value_counts(), ax = B)\n",
    "sns.barplot(working_df.sign_mean_log2FC_2.value_counts(), ax = C)\n",
    "sns.barplot(working_df.sign_mean_log2FC_3.value_counts(), ax = D)\n",
    "sns.barplot(working_df.significant_dir_1.value_counts(), ax = E)\n",
    "\n",
    "\n",
    "A.set_title(\"Differential Accessibility across patients (boolean) [A]\")\n",
    "B.set_title(\"Differential Accessibility direction (v = 1) [B]\")\n",
    "C.set_title(\"Differential Accessibility direction (v = 2) [C]\")\n",
    "D.set_title(\"Differential Accessibility direction (v = 3) [D]\")\n",
    "E.set_title(\"Signficant Direction (v = 1) [E]\")\n",
    "\n",
    "A.set_xlabel(\"\"); A.set_ylabel(\"\")\n",
    "B.set_xlabel(\"\"); B.set_ylabel(\"\")\n",
    "C.set_xlabel(\"\"); C.set_ylabel(\"\")\n",
    "D.set_xlabel(\"\"); D.set_ylabel(\"\")\n",
    "E.set_xlabel(\"\"); E.set_ylabel(\"\")\n",
    "\n",
    "F.axis('off')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ids = working_df[[\"bin\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.drop(cols_to_drop, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean.GC.content</th>\n",
       "      <th>total_n_partners.trans</th>\n",
       "      <th>total_n_PPIs.trans_IntINSIDER</th>\n",
       "      <th>total_n_ohnologs.mmpaper_trans</th>\n",
       "      <th>total_n_paralogs_trans</th>\n",
       "      <th>dist.to.closest.FGS</th>\n",
       "      <th>Length_Counts.E1</th>\n",
       "      <th>Length_Counts.E10</th>\n",
       "      <th>Length_Counts.E11</th>\n",
       "      <th>Length_Counts.E12</th>\n",
       "      <th>...</th>\n",
       "      <th>HAPLOscore_pancancer</th>\n",
       "      <th>Density.complex.proteins</th>\n",
       "      <th>Density.Ohnologs</th>\n",
       "      <th>Chromosome_Length</th>\n",
       "      <th>Centromere_Length</th>\n",
       "      <th>Centromere_Type</th>\n",
       "      <th>n_of_cancer_genes</th>\n",
       "      <th>n_of_TSGs</th>\n",
       "      <th>n_of_OGs</th>\n",
       "      <th>significant_dir_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.640</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61798000.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249250621</td>\n",
       "      <td>2906265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27119981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249250621</td>\n",
       "      <td>2906265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27220001.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249250621</td>\n",
       "      <td>2906265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27320021.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249250621</td>\n",
       "      <td>2906265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27420041.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249250621</td>\n",
       "      <td>2906265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25236</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141213431</td>\n",
       "      <td>2128923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25237</th>\n",
       "      <td>38.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>141213431</td>\n",
       "      <td>2128923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25238</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141213431</td>\n",
       "      <td>2128923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25239</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141213431</td>\n",
       "      <td>2128923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141213431</td>\n",
       "      <td>2128923</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25240 rows  53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean.GC.content  total_n_partners.trans  total_n_PPIs.trans_IntINSIDER  \\\n",
       "1               47.640                     2.0                           11.0   \n",
       "2                  NaN                     NaN                            NaN   \n",
       "3                  NaN                     NaN                            NaN   \n",
       "4               37.780                     0.0                            0.0   \n",
       "5                  NaN                     NaN                            NaN   \n",
       "...                ...                     ...                            ...   \n",
       "25236              NaN                     NaN                            NaN   \n",
       "25237           38.875                     0.0                           21.0   \n",
       "25238              NaN                     NaN                            NaN   \n",
       "25239              NaN                     NaN                            NaN   \n",
       "25240              NaN                     NaN                            NaN   \n",
       "\n",
       "       total_n_ohnologs.mmpaper_trans  total_n_paralogs_trans  \\\n",
       "1                                 NaN                     NaN   \n",
       "2                                 NaN                     NaN   \n",
       "3                                 NaN                     NaN   \n",
       "4                                 NaN                     1.0   \n",
       "5                                 NaN                     NaN   \n",
       "...                               ...                     ...   \n",
       "25236                             NaN                     NaN   \n",
       "25237                            14.0                    22.0   \n",
       "25238                             NaN                     NaN   \n",
       "25239                             NaN                     NaN   \n",
       "25240                             NaN                     NaN   \n",
       "\n",
       "       dist.to.closest.FGS  Length_Counts.E1  Length_Counts.E10  \\\n",
       "1               61798000.0             600.0             2800.0   \n",
       "2               27119981.0               0.0                0.0   \n",
       "3               27220001.0             600.0                0.0   \n",
       "4               27320021.0               0.0                0.0   \n",
       "5               27420041.0            1100.0                0.0   \n",
       "...                    ...               ...                ...   \n",
       "25236                  NaN             900.0                0.0   \n",
       "25237                  NaN             500.0                0.0   \n",
       "25238                  NaN             500.0                0.0   \n",
       "25239                  NaN            1400.0              600.0   \n",
       "25240                  NaN               0.0                0.0   \n",
       "\n",
       "       Length_Counts.E11  Length_Counts.E12  ...  HAPLOscore_pancancer  \\\n",
       "1                 4100.0             3600.0  ...                   0.0   \n",
       "2                    0.0                0.0  ...                   NaN   \n",
       "3                    0.0                0.0  ...                   NaN   \n",
       "4                    0.0                0.0  ...                   0.0   \n",
       "5                    0.0              200.0  ...                   NaN   \n",
       "...                  ...                ...  ...                   ...   \n",
       "25236               53.0                0.0  ...                   NaN   \n",
       "25237                0.0              200.0  ...                   0.0   \n",
       "25238                0.0              600.0  ...                   NaN   \n",
       "25239                0.0              600.0  ...                   NaN   \n",
       "25240                0.0                0.0  ...                   NaN   \n",
       "\n",
       "       Density.complex.proteins  Density.Ohnologs  Chromosome_Length  \\\n",
       "1                           0.5               0.0          249250621   \n",
       "2                           NaN               NaN          249250621   \n",
       "3                           NaN               NaN          249250621   \n",
       "4                           0.0               0.0          249250621   \n",
       "5                           NaN               NaN          249250621   \n",
       "...                         ...               ...                ...   \n",
       "25236                       NaN               NaN          141213431   \n",
       "25237                       0.0               0.5          141213431   \n",
       "25238                       NaN               NaN          141213431   \n",
       "25239                       NaN               NaN          141213431   \n",
       "25240                       NaN               NaN          141213431   \n",
       "\n",
       "       Centromere_Length  Centromere_Type  n_of_cancer_genes  n_of_TSGs  \\\n",
       "1                2906265                0                  0          0   \n",
       "2                2906265                0                  0          0   \n",
       "3                2906265                0                  0          0   \n",
       "4                2906265                0                  0          0   \n",
       "5                2906265                0                  0          0   \n",
       "...                  ...              ...                ...        ...   \n",
       "25236            2128923                1                  0          0   \n",
       "25237            2128923                1                  0          0   \n",
       "25238            2128923                1                  0          0   \n",
       "25239            2128923                1                  0          0   \n",
       "25240            2128923                1                  0          0   \n",
       "\n",
       "       n_of_OGs  significant_dir_1  \n",
       "1             0                  1  \n",
       "2             0                  1  \n",
       "3             0                  1  \n",
       "4             0                  0  \n",
       "5             0                  1  \n",
       "...         ...                ...  \n",
       "25236         0                  1  \n",
       "25237         0                  1  \n",
       "25238         0                  1  \n",
       "25239         0                  1  \n",
       "25240         0                  1  \n",
       "\n",
       "[25240 rows x 53 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = working_df.iloc[:, 0:-1]\n",
    "y = working_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"significant_dir_1\" in X.columns:\n",
    "    raise Exception(\"Target Variable in the training set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean.GC.content', 'total_n_partners.trans',\n",
       "       'total_n_PPIs.trans_IntINSIDER', 'total_n_ohnologs.mmpaper_trans',\n",
       "       'total_n_paralogs_trans', 'dist.to.closest.FGS', 'Length_Counts.E1',\n",
       "       'Length_Counts.E10', 'Length_Counts.E11', 'Length_Counts.E12',\n",
       "       'Length_Counts.E13', 'Length_Counts.E14', 'Length_Counts.E15',\n",
       "       'Length_Counts.E16', 'Length_Counts.E17', 'Length_Counts.E18',\n",
       "       'Length_Counts.E19', 'Length_Counts.E2', 'Length_Counts.E20',\n",
       "       'Length_Counts.E21', 'Length_Counts.E22', 'Length_Counts.E23',\n",
       "       'Length_Counts.E24', 'Length_Counts.E25', 'Length_Counts.E3',\n",
       "       'Length_Counts.E4', 'Length_Counts.E5', 'Length_Counts.E6',\n",
       "       'Length_Counts.E7', 'Length_Counts.E8', 'Length_Counts.E9',\n",
       "       'all.int.trans_IntINSIDER', 'genes.bin', 'partners.trans', 'density.OG',\n",
       "       'density.TSG', 'dist.to.closest.OG', 'dist.to.closest.TSG',\n",
       "       'mutations_norm', 'distance.to.centromere', 'distance.to.telomere',\n",
       "       'Ess.distance_pancancer', 'ESSscore_pancancer', 'HAPLOscore_pancancer',\n",
       "       'Density.complex.proteins', 'Density.Ohnologs', 'Chromosome_Length',\n",
       "       'Centromere_Length', 'Centromere_Type', 'n_of_cancer_genes',\n",
       "       'n_of_TSGs', 'n_of_OGs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, bin_train, bin_test = sk.model_selection.train_test_split(X, y, bin_ids, test_size=0.3, random_state=split_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Classifier and the Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = xgb.XGBClassifier(n_jobs = n_jobs, nthread = nthread, seed = classifier_seed, random_state = classifier_random_state)\n",
    "\n",
    "search_space_bayes = {  \n",
    "    'learning_rate': (0.001, 1.0, 'log-uniform'),  \n",
    "    'n_estimators': (50, 500),  \n",
    "    'max_depth': (3, 15),  \n",
    "    'min_child_weight': (1, 10),  \n",
    "    'gamma': (1e-9, 5.0, 'log-uniform'),  \n",
    "    'subsample': (0.5, 1.0, 'uniform'),  \n",
    "    'colsample_bytree': (0.5, 1.0, 'uniform'),  \n",
    "    'colsample_bylevel': (0.5, 1.0, 'uniform'),  \n",
    "    'reg_alpha': (1e-9, 10.0, 'log-uniform'),  \n",
    "    'reg_lambda': (1e-9, 10.0, 'log-uniform'),  \n",
    "    'max_delta_step': (0, 10),  \n",
    "    'objective': ['multi:softmax'],  \n",
    "    'booster': ['gbtree', 'dart'],  \n",
    "    'eval_metric': ['mlogloss', 'error', 'auc']  \n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NESTED CV PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.755 total time= 6.0min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.771 total time=   4.3s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 6.0min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.774 total time=   4.2s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.768 total time=   9.1s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.770 total time=   9.1s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.775 total time=  12.8s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.775 total time=  13.0s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.759 total time=   2.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.758 total time=   2.1s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.771 total time=12.3min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.767 total time=   3.8s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.771 total time=12.4min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.771 total time=   3.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.743 total time=14.3min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.759 total time=   1.9s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.744 total time=14.4min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.766 total time=   1.8s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.771 total time=   2.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.768 total time=   2.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8467569259497714, eval_metric=auc, gamma=0.1877197701989184, learning_rate=0.01815051507791742, max_delta_step=0, max_depth=12, min_child_weight=1, n_estimators=372, objective=multi:softmax, reg_alpha=3.547845967739137e-07, reg_lambda=8.307023946474508e-07, subsample=0.5506416778183526;, score=0.778 total time=  12.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.8467569259497714, eval_metric=auc, gamma=0.1877197701989184, learning_rate=0.01815051507791742, max_delta_step=0, max_depth=12, min_child_weight=1, n_estimators=372, objective=multi:softmax, reg_alpha=3.547845967739137e-07, reg_lambda=8.307023946474508e-07, subsample=0.5506416778183526;, score=0.776 total time=  12.5s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9244266416864042, eval_metric=auc, gamma=1e-09, learning_rate=0.16903343077639768, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=86, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=0.0011471735989222942, subsample=1.0;, score=0.771 total time=   1.5s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9244266416864042, eval_metric=auc, gamma=1e-09, learning_rate=0.16903343077639768, max_delta_step=4, max_depth=15, min_child_weight=10, n_estimators=86, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=0.0011471735989222942, subsample=1.0;, score=0.771 total time=   1.5s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.6707738714145416, eval_metric=auc, gamma=7.368830625777265e-09, learning_rate=0.025659219265651456, max_delta_step=10, max_depth=8, min_child_weight=10, n_estimators=220, objective=multi:softmax, reg_alpha=0.39031724554240754, reg_lambda=0.01506326998538553, subsample=0.9951195629342775;, score=0.778 total time= 2.9min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.6707738714145416, eval_metric=auc, gamma=7.368830625777265e-09, learning_rate=0.025659219265651456, max_delta_step=10, max_depth=8, min_child_weight=10, n_estimators=220, objective=multi:softmax, reg_alpha=0.39031724554240754, reg_lambda=0.01506326998538553, subsample=0.9951195629342775;, score=0.775 total time= 2.9min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9448549932363053, colsample_bytree=0.8320689717556198, eval_metric=auc, gamma=0.00012492541879202587, learning_rate=0.06324113176951025, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=368, objective=multi:softmax, reg_alpha=5.720808085700062e-07, reg_lambda=4.736695949290859e-06, subsample=0.6136530681499632;, score=0.776 total time= 9.2min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.5275349936173942, eval_metric=auc, gamma=0.020607733992966407, learning_rate=0.0013725956437453091, max_delta_step=0, max_depth=8, min_child_weight=1, n_estimators=191, objective=multi:softmax, reg_alpha=8.32877101881315e-08, reg_lambda=1.343169408667581e-06, subsample=0.7980113078842603;, score=0.768 total time= 2.2min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5166938424329077, colsample_bytree=0.7974201244755831, eval_metric=auc, gamma=6.091016072839037e-09, learning_rate=0.2136334251745222, max_delta_step=10, max_depth=9, min_child_weight=9, n_estimators=401, objective=multi:softmax, reg_alpha=0.00588986683150407, reg_lambda=0.005664948133868906, subsample=0.7642372999232436;, score=0.769 total time= 9.5min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9027274712937241, colsample_bytree=0.9203732192765637, eval_metric=error, gamma=5.308129357925039e-08, learning_rate=0.027498538529907954, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=73, objective=multi:softmax, reg_alpha=1.960462326510245e-09, reg_lambda=0.06916895344869514, subsample=0.7423498260328163;, score=0.768 total time=  17.8s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9448549932363053, colsample_bytree=0.8320689717556198, eval_metric=auc, gamma=0.00012492541879202587, learning_rate=0.06324113176951025, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=368, objective=multi:softmax, reg_alpha=5.720808085700062e-07, reg_lambda=4.736695949290859e-06, subsample=0.6136530681499632;, score=0.776 total time= 9.2min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.5275349936173942, eval_metric=auc, gamma=0.020607733992966407, learning_rate=0.0013725956437453091, max_delta_step=0, max_depth=8, min_child_weight=1, n_estimators=191, objective=multi:softmax, reg_alpha=8.32877101881315e-08, reg_lambda=1.343169408667581e-06, subsample=0.7980113078842603;, score=0.770 total time= 2.2min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5166938424329077, colsample_bytree=0.7974201244755831, eval_metric=auc, gamma=6.091016072839037e-09, learning_rate=0.2136334251745222, max_delta_step=10, max_depth=9, min_child_weight=9, n_estimators=401, objective=multi:softmax, reg_alpha=0.00588986683150407, reg_lambda=0.005664948133868906, subsample=0.7642372999232436;, score=0.768 total time= 9.5min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9027274712937241, colsample_bytree=0.9203732192765637, eval_metric=error, gamma=5.308129357925039e-08, learning_rate=0.027498538529907954, max_delta_step=2, max_depth=4, min_child_weight=9, n_estimators=73, objective=multi:softmax, reg_alpha=1.960462326510245e-09, reg_lambda=0.06916895344869514, subsample=0.7423498260328163;, score=0.771 total time=  17.7s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.6702627013623446, eval_metric=auc, gamma=1.375309957422596e-06, learning_rate=0.5499920637025257, max_delta_step=6, max_depth=4, min_child_weight=10, n_estimators=298, objective=multi:softmax, reg_alpha=0.5634769981495499, reg_lambda=1.8189005475851754e-08, subsample=0.951915974585722;, score=0.759 total time=   1.0s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.6702627013623446, eval_metric=auc, gamma=1.375309957422596e-06, learning_rate=0.5499920637025257, max_delta_step=6, max_depth=4, min_child_weight=10, n_estimators=298, objective=multi:softmax, reg_alpha=0.5634769981495499, reg_lambda=1.8189005475851754e-08, subsample=0.951915974585722;, score=0.761 total time=   1.0s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6900363210702266, colsample_bytree=0.5241360810725438, eval_metric=mlogloss, gamma=1.8662915914028178, learning_rate=0.8578520114428799, max_delta_step=7, max_depth=8, min_child_weight=1, n_estimators=50, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=6.460882912266555e-05, subsample=0.5063159422411804;, score=0.726 total time=   0.3s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6900363210702266, colsample_bytree=0.5241360810725438, eval_metric=mlogloss, gamma=1.8662915914028178, learning_rate=0.8578520114428799, max_delta_step=7, max_depth=8, min_child_weight=1, n_estimators=50, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=6.460882912266555e-05, subsample=0.5063159422411804;, score=0.735 total time=   0.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6503508280046024, colsample_bytree=1.0, eval_metric=mlogloss, gamma=0.01337902061960297, learning_rate=0.0022043805718087823, max_delta_step=2, max_depth=11, min_child_weight=10, n_estimators=274, objective=multi:softmax, reg_alpha=0.0007653398190823693, reg_lambda=2.691001867522122e-09, subsample=0.6892978514867252;, score=0.769 total time= 4.7min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6503508280046024, colsample_bytree=1.0, eval_metric=mlogloss, gamma=0.01337902061960297, learning_rate=0.0022043805718087823, max_delta_step=2, max_depth=11, min_child_weight=10, n_estimators=274, objective=multi:softmax, reg_alpha=0.0007653398190823693, reg_lambda=2.691001867522122e-09, subsample=0.6892978514867252;, score=0.774 total time= 4.7min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6678594657015935, colsample_bytree=1.0, eval_metric=error, gamma=4.185147819815875e-08, learning_rate=0.001, max_delta_step=3, max_depth=6, min_child_weight=7, n_estimators=69, objective=multi:softmax, reg_alpha=3.02026044143198e-09, reg_lambda=0.00020027762072086794, subsample=0.6970139708612062;, score=0.771 total time=  16.7s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9860089903321492, eval_metric=mlogloss, gamma=1.0645505043966828, learning_rate=0.3304086479695763, max_delta_step=9, max_depth=14, min_child_weight=1, n_estimators=428, objective=multi:softmax, reg_alpha=0.13518452294291755, reg_lambda=10.0, subsample=0.8015272607539554;, score=0.772 total time=   1.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6678594657015935, colsample_bytree=1.0, eval_metric=error, gamma=4.185147819815875e-08, learning_rate=0.001, max_delta_step=3, max_depth=6, min_child_weight=7, n_estimators=69, objective=multi:softmax, reg_alpha=3.02026044143198e-09, reg_lambda=0.00020027762072086794, subsample=0.6970139708612062;, score=0.768 total time=  16.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9860089903321492, eval_metric=mlogloss, gamma=1.0645505043966828, learning_rate=0.3304086479695763, max_delta_step=9, max_depth=14, min_child_weight=1, n_estimators=428, objective=multi:softmax, reg_alpha=0.13518452294291755, reg_lambda=10.0, subsample=0.8015272607539554;, score=0.774 total time=   1.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.8703042546338926, colsample_bytree=0.6857822279956838, eval_metric=auc, gamma=4.6455804878282794e-07, learning_rate=0.29148689292420177, max_delta_step=3, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=0.0010461595417729363, subsample=0.6132841293156311;, score=0.773 total time=   9.2s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.6654842028345188, eval_metric=auc, gamma=0.002272878628426508, learning_rate=0.0010771053109007857, max_delta_step=3, max_depth=11, min_child_weight=1, n_estimators=477, objective=multi:softmax, reg_alpha=8.470014924390966, reg_lambda=10.0, subsample=0.6073075921971499;, score=0.762 total time=13.7min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9907377987466541, colsample_bytree=0.873567576006471, eval_metric=auc, gamma=1.9262541344214606e-05, learning_rate=0.008977597430961725, max_delta_step=9, max_depth=13, min_child_weight=5, n_estimators=297, objective=multi:softmax, reg_alpha=3.0259677611541733e-06, reg_lambda=0.0009205620580446416, subsample=0.7807588279891484;, score=0.777 total time=  11.3s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.8703042546338926, colsample_bytree=0.6857822279956838, eval_metric=auc, gamma=4.6455804878282794e-07, learning_rate=0.29148689292420177, max_delta_step=3, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=0.0010461595417729363, subsample=0.6132841293156311;, score=0.772 total time=   9.2s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.6654842028345188, eval_metric=auc, gamma=0.002272878628426508, learning_rate=0.0010771053109007857, max_delta_step=3, max_depth=11, min_child_weight=1, n_estimators=477, objective=multi:softmax, reg_alpha=8.470014924390966, reg_lambda=10.0, subsample=0.6073075921971499;, score=0.760 total time=13.8min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9907377987466541, colsample_bytree=0.873567576006471, eval_metric=auc, gamma=1.9262541344214606e-05, learning_rate=0.008977597430961725, max_delta_step=9, max_depth=13, min_child_weight=5, n_estimators=297, objective=multi:softmax, reg_alpha=3.0259677611541733e-06, reg_lambda=0.0009205620580446416, subsample=0.7807588279891484;, score=0.777 total time=  10.7s\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.769 total time=   3.5s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.770 total time=   3.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.775 total time=   5.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.777 total time=   5.5s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.758 total time=   1.1s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.754 total time=   1.1s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.773 total time= 4.4min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.778 total time= 4.4min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 2.9min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.769 total time=   2.9s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 2.9min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.771 total time=   1.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.773 total time=   1.8s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.743 total time= 5.0min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.767 total time=   1.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.776 total time=   2.0s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.749 total time= 5.1min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.765 total time=   1.3s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.770 total time=   1.5s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.768 total time=   1.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6325576454878998, colsample_bytree=0.9137526448154984, eval_metric=auc, gamma=3.5012507677661425e-09, learning_rate=0.10902336670518316, max_delta_step=10, max_depth=6, min_child_weight=4, n_estimators=377, objective=multi:softmax, reg_alpha=1.6586686230612084e-09, reg_lambda=1.107990651974232, subsample=0.9171184111926207;, score=0.778 total time= 4.1min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.8948418646566472, colsample_bytree=0.5480530864834537, eval_metric=auc, gamma=0.33250064057197387, learning_rate=0.0028801181430354247, max_delta_step=6, max_depth=5, min_child_weight=3, n_estimators=64, objective=multi:softmax, reg_alpha=4.806283397912895e-05, reg_lambda=1.9111539242018057e-08, subsample=1.0;, score=0.761 total time=   7.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6325576454878998, colsample_bytree=0.9137526448154984, eval_metric=auc, gamma=3.5012507677661425e-09, learning_rate=0.10902336670518316, max_delta_step=10, max_depth=6, min_child_weight=4, n_estimators=377, objective=multi:softmax, reg_alpha=1.6586686230612084e-09, reg_lambda=1.107990651974232, subsample=0.9171184111926207;, score=0.776 total time= 4.1min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.8948418646566472, colsample_bytree=0.5480530864834537, eval_metric=auc, gamma=0.33250064057197387, learning_rate=0.0028801181430354247, max_delta_step=6, max_depth=5, min_child_weight=3, n_estimators=64, objective=multi:softmax, reg_alpha=4.806283397912895e-05, reg_lambda=1.9111539242018057e-08, subsample=1.0;, score=0.761 total time=   7.2s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.8565254395633433, eval_metric=auc, gamma=0.2870077870061158, learning_rate=0.6180715022698205, max_delta_step=10, max_depth=4, min_child_weight=5, n_estimators=319, objective=multi:softmax, reg_alpha=2.0163753588822813e-08, reg_lambda=1.1267258884967492e-05, subsample=0.5;, score=0.744 total time= 2.9min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6321885268509125, colsample_bytree=0.9249259800291418, eval_metric=auc, gamma=5.3412943536034783e-08, learning_rate=0.026358947890681512, max_delta_step=10, max_depth=12, min_child_weight=3, n_estimators=435, objective=multi:softmax, reg_alpha=4.671118039158637e-06, reg_lambda=4.312365349749594, subsample=0.8986293780226979;, score=0.780 total time= 6.5min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, eval_metric=auc, gamma=0.21783558410969994, learning_rate=0.0030555265699691424, max_delta_step=1, max_depth=3, min_child_weight=4, n_estimators=382, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=10.0, subsample=0.6601433519430572;, score=0.767 total time=   0.9s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.8565254395633433, eval_metric=auc, gamma=0.2870077870061158, learning_rate=0.6180715022698205, max_delta_step=10, max_depth=4, min_child_weight=5, n_estimators=319, objective=multi:softmax, reg_alpha=2.0163753588822813e-08, reg_lambda=1.1267258884967492e-05, subsample=0.5;, score=0.748 total time= 2.9min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6321885268509125, colsample_bytree=0.9249259800291418, eval_metric=auc, gamma=5.3412943536034783e-08, learning_rate=0.026358947890681512, max_delta_step=10, max_depth=12, min_child_weight=3, n_estimators=435, objective=multi:softmax, reg_alpha=4.671118039158637e-06, reg_lambda=4.312365349749594, subsample=0.8986293780226979;, score=0.776 total time= 6.5min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, eval_metric=auc, gamma=0.21783558410969994, learning_rate=0.0030555265699691424, max_delta_step=1, max_depth=3, min_child_weight=4, n_estimators=382, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=10.0, subsample=0.6601433519430572;, score=0.766 total time=   0.8s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.7507514490880656, colsample_bytree=0.5169401994050105, eval_metric=auc, gamma=0.5425587840361098, learning_rate=0.014609725730326312, max_delta_step=1, max_depth=12, min_child_weight=4, n_estimators=307, objective=multi:softmax, reg_alpha=8.534387692387837, reg_lambda=0.003494794644093283, subsample=0.660258169202777;, score=0.772 total time=   1.6s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.7507514490880656, colsample_bytree=0.5169401994050105, eval_metric=auc, gamma=0.5425587840361098, learning_rate=0.014609725730326312, max_delta_step=1, max_depth=12, min_child_weight=4, n_estimators=307, objective=multi:softmax, reg_alpha=8.534387692387837, reg_lambda=0.003494794644093283, subsample=0.660258169202777;, score=0.771 total time=   1.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "STEP 3 (Prediction)\n",
      "Fold #2\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5, colsample_bytree=0.6948433584315258, eval_metric=auc, gamma=0.10810090615377771, learning_rate=0.001, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=355, objective=multi:softmax, reg_alpha=9.999966348969743, reg_lambda=10.0, subsample=1.0;, score=0.761 total time= 4.1min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6299951445087593, colsample_bytree=0.9674864362383246, eval_metric=auc, gamma=0.0003375716331052469, learning_rate=0.0923144140482049, max_delta_step=10, max_depth=12, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=8.799759820143296e-06, reg_lambda=5.4457767594646755, subsample=0.5;, score=0.778 total time=   6.3s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5, colsample_bytree=0.6948433584315258, eval_metric=auc, gamma=0.10810090615377771, learning_rate=0.001, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=355, objective=multi:softmax, reg_alpha=9.999966348969743, reg_lambda=10.0, subsample=1.0;, score=0.762 total time= 4.1min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6299951445087593, colsample_bytree=0.9674864362383246, eval_metric=auc, gamma=0.0003375716331052469, learning_rate=0.0923144140482049, max_delta_step=10, max_depth=12, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=8.799759820143296e-06, reg_lambda=5.4457767594646755, subsample=0.5;, score=0.774 total time=   6.2s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9719596966140315, colsample_bytree=0.5, eval_metric=error, gamma=1e-09, learning_rate=0.020863573525417418, max_delta_step=0, max_depth=15, min_child_weight=4, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0;, score=0.760 total time=   0.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9999841463481054, colsample_bytree=0.6021504234286239, eval_metric=mlogloss, gamma=0.003184485322573541, learning_rate=0.006678258361703003, max_delta_step=0, max_depth=3, min_child_weight=9, n_estimators=278, objective=multi:softmax, reg_alpha=2.985723797134811e-07, reg_lambda=8.22096125533794, subsample=0.6130417164736437;, score=0.759 total time= 2.1min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9719596966140315, colsample_bytree=0.5, eval_metric=error, gamma=1e-09, learning_rate=0.020863573525417418, max_delta_step=0, max_depth=15, min_child_weight=4, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=1.0;, score=0.757 total time=   0.3s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9999841463481054, colsample_bytree=0.6021504234286239, eval_metric=mlogloss, gamma=0.003184485322573541, learning_rate=0.006678258361703003, max_delta_step=0, max_depth=3, min_child_weight=9, n_estimators=278, objective=multi:softmax, reg_alpha=2.985723797134811e-07, reg_lambda=8.22096125533794, subsample=0.6130417164736437;, score=0.757 total time= 2.1min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6828045516451303, colsample_bytree=0.5, eval_metric=auc, gamma=0.9772962925984783, learning_rate=0.08537525595466836, max_delta_step=2, max_depth=12, min_child_weight=1, n_estimators=436, objective=multi:softmax, reg_alpha=0.6503437510460018, reg_lambda=0.026900053342257722, subsample=0.7711728537422696;, score=0.778 total time=   1.0s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7745002465151616, eval_metric=mlogloss, gamma=0.09939961912351379, learning_rate=0.0023466970647889112, max_delta_step=10, max_depth=13, min_child_weight=7, n_estimators=50, objective=multi:softmax, reg_alpha=0.04848019172664181, reg_lambda=3.1498024113987695, subsample=0.7754508064970582;, score=0.769 total time=   0.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6828045516451303, colsample_bytree=0.5, eval_metric=auc, gamma=0.9772962925984783, learning_rate=0.08537525595466836, max_delta_step=2, max_depth=12, min_child_weight=1, n_estimators=436, objective=multi:softmax, reg_alpha=0.6503437510460018, reg_lambda=0.026900053342257722, subsample=0.7711728537422696;, score=0.779 total time=   1.0s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.7745002465151616, eval_metric=mlogloss, gamma=0.09939961912351379, learning_rate=0.0023466970647889112, max_delta_step=10, max_depth=13, min_child_weight=7, n_estimators=50, objective=multi:softmax, reg_alpha=0.04848019172664181, reg_lambda=3.1498024113987695, subsample=0.7754508064970582;, score=0.770 total time=   0.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.7246588529054766, colsample_bytree=1.0, eval_metric=auc, gamma=0.042181794909130536, learning_rate=0.4135697931574479, max_delta_step=1, max_depth=9, min_child_weight=2, n_estimators=167, objective=multi:softmax, reg_alpha=2.866081421686224e-06, reg_lambda=0.000383889778006149, subsample=1.0;, score=0.769 total time=   0.6s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.7697922594364408, colsample_bytree=1.0, eval_metric=mlogloss, gamma=0.07416140315421552, learning_rate=0.06422677849481145, max_delta_step=2, max_depth=3, min_child_weight=4, n_estimators=250, objective=multi:softmax, reg_alpha=4.882622150063768, reg_lambda=10.0, subsample=0.5857350010223874;, score=0.772 total time= 1.7min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.7246588529054766, colsample_bytree=1.0, eval_metric=auc, gamma=0.042181794909130536, learning_rate=0.4135697931574479, max_delta_step=1, max_depth=9, min_child_weight=2, n_estimators=167, objective=multi:softmax, reg_alpha=2.866081421686224e-06, reg_lambda=0.000383889778006149, subsample=1.0;, score=0.771 total time=   0.6s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.7697922594364408, colsample_bytree=1.0, eval_metric=mlogloss, gamma=0.07416140315421552, learning_rate=0.06422677849481145, max_delta_step=2, max_depth=3, min_child_weight=4, n_estimators=250, objective=multi:softmax, reg_alpha=4.882622150063768, reg_lambda=10.0, subsample=0.5857350010223874;, score=0.772 total time= 1.9min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6631941461684973, colsample_bytree=0.9879291244794413, eval_metric=auc, gamma=3.892485925614548e-07, learning_rate=0.001994123811547627, max_delta_step=6, max_depth=13, min_child_weight=8, n_estimators=155, objective=multi:softmax, reg_alpha=1.6983180276099548e-09, reg_lambda=0.0007718312561034333, subsample=0.7594072097223057;, score=0.774 total time=  52.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 5.8min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.773 total time=   3.0s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6631941461684973, colsample_bytree=0.9879291244794413, eval_metric=auc, gamma=3.892485925614548e-07, learning_rate=0.001994123811547627, max_delta_step=6, max_depth=13, min_child_weight=8, n_estimators=155, objective=multi:softmax, reg_alpha=1.6983180276099548e-09, reg_lambda=0.0007718312561034333, subsample=0.7594072097223057;, score=0.773 total time=  52.6s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 5.9min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.772 total time=   3.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.772 total time=   6.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.768 total time=   6.8s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.775 total time=   8.9s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.773 total time=   9.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.752 total time=   1.5s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.753 total time=   1.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.767 total time= 8.3min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.763 total time=   2.8s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.775 total time= 8.4min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.765 total time=   2.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.737 total time= 9.9min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.762 total time=   1.9s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.744 total time=10.0min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.763 total time=   1.7s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.770 total time=   2.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.770 total time=   2.5s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6465719336752642, colsample_bytree=0.6915028133120708, eval_metric=auc, gamma=0.09372804183776498, learning_rate=0.0011486723725073365, max_delta_step=2, max_depth=4, min_child_weight=1, n_estimators=278, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=7.319643827462993e-05, subsample=0.6890559212231506;, score=0.760 total time= 4.4min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, eval_metric=auc, gamma=1e-09, learning_rate=1.0, max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.5;, score=0.730 total time=   1.7s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6465719336752642, colsample_bytree=0.6915028133120708, eval_metric=auc, gamma=0.09372804183776498, learning_rate=0.0011486723725073365, max_delta_step=2, max_depth=4, min_child_weight=1, n_estimators=278, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=7.319643827462993e-05, subsample=0.6890559212231506;, score=0.760 total time= 4.4min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=1.0, eval_metric=auc, gamma=1e-09, learning_rate=1.0, max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=1e-09, subsample=0.5;, score=0.736 total time=   1.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9503978525489797, eval_metric=auc, gamma=0.00014515999465442814, learning_rate=0.16434915161162297, max_delta_step=10, max_depth=6, min_child_weight=10, n_estimators=136, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=9.335500777795789e-08, subsample=0.5681430456751273;, score=0.765 total time=   1.0s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6694306413873439, colsample_bytree=0.7236821753438354, eval_metric=auc, gamma=2.281915509268367e-09, learning_rate=0.003105118366741572, max_delta_step=3, max_depth=9, min_child_weight=10, n_estimators=276, objective=multi:softmax, reg_alpha=3.4314421757019056e-05, reg_lambda=0.0005090073686000737, subsample=0.5257323114502169;, score=0.770 total time=   3.0s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.9503978525489797, eval_metric=auc, gamma=0.00014515999465442814, learning_rate=0.16434915161162297, max_delta_step=10, max_depth=6, min_child_weight=10, n_estimators=136, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=9.335500777795789e-08, subsample=0.5681430456751273;, score=0.771 total time=   1.4s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6694306413873439, colsample_bytree=0.7236821753438354, eval_metric=auc, gamma=2.281915509268367e-09, learning_rate=0.003105118366741572, max_delta_step=3, max_depth=9, min_child_weight=10, n_estimators=276, objective=multi:softmax, reg_alpha=3.4314421757019056e-05, reg_lambda=0.0005090073686000737, subsample=0.5257323114502169;, score=0.768 total time=   3.1s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5766062338709224, colsample_bytree=0.5355871115873073, eval_metric=auc, gamma=0.0003503772882325358, learning_rate=0.9933204829878856, max_delta_step=10, max_depth=14, min_child_weight=10, n_estimators=103, objective=multi:softmax, reg_alpha=1.1319981530346643e-09, reg_lambda=0.6073183263306643, subsample=0.9459223249467141;, score=0.751 total time=  39.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.7505751594068718, colsample_bytree=1.0, eval_metric=error, gamma=4.999999999999999, learning_rate=0.038640924838001446, max_delta_step=10, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=1e-09, subsample=0.7083797455121685;, score=0.765 total time=   0.2s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5766062338709224, colsample_bytree=0.5355871115873073, eval_metric=auc, gamma=0.0003503772882325358, learning_rate=0.9933204829878856, max_delta_step=10, max_depth=14, min_child_weight=10, n_estimators=103, objective=multi:softmax, reg_alpha=1.1319981530346643e-09, reg_lambda=0.6073183263306643, subsample=0.9459223249467141;, score=0.748 total time=  40.9s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.7505751594068718, colsample_bytree=1.0, eval_metric=error, gamma=4.999999999999999, learning_rate=0.038640924838001446, max_delta_step=10, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=10.0, reg_lambda=1e-09, subsample=0.7083797455121685;, score=0.765 total time=   0.3s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=error, gamma=4.999999999999999, learning_rate=0.004023844521122314, max_delta_step=0, max_depth=3, min_child_weight=10, n_estimators=262, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=4.146564945643226e-05, subsample=1.0;, score=0.756 total time=   0.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=error, gamma=4.999999999999999, learning_rate=0.004023844521122314, max_delta_step=0, max_depth=3, min_child_weight=10, n_estimators=262, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=4.146564945643226e-05, subsample=1.0;, score=0.757 total time=   0.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6884376034476656, colsample_bytree=1.0, eval_metric=error, gamma=1e-09, learning_rate=0.0039888203023127795, max_delta_step=10, max_depth=15, min_child_weight=5, n_estimators=413, objective=multi:softmax, reg_alpha=4.9938595901632565, reg_lambda=1e-09, subsample=0.5160178893156563;, score=0.773 total time=10.6min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8106976786785483, colsample_bytree=1.0, eval_metric=auc, gamma=1e-09, learning_rate=0.030091031042849624, max_delta_step=2, max_depth=3, min_child_weight=9, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8336945303735622;, score=0.771 total time=   1.6s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6884376034476656, colsample_bytree=1.0, eval_metric=error, gamma=1e-09, learning_rate=0.0039888203023127795, max_delta_step=10, max_depth=15, min_child_weight=5, n_estimators=413, objective=multi:softmax, reg_alpha=4.9938595901632565, reg_lambda=1e-09, subsample=0.5160178893156563;, score=0.770 total time=10.6min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8106976786785483, colsample_bytree=1.0, eval_metric=auc, gamma=1e-09, learning_rate=0.030091031042849624, max_delta_step=2, max_depth=3, min_child_weight=9, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=0.8336945303735622;, score=0.771 total time=   1.4s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=auc, gamma=4.999999999999999, learning_rate=0.007682086714025019, max_delta_step=10, max_depth=15, min_child_weight=10, n_estimators=259, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=0.031426891696904255, subsample=1.0;, score=0.771 total time= 3.9min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=auc, gamma=4.999999999999999, learning_rate=0.007682086714025019, max_delta_step=10, max_depth=15, min_child_weight=10, n_estimators=259, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=0.031426891696904255, subsample=1.0;, score=0.768 total time= 3.9min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "STEP 2.2 (SHAP)\n",
      "STEP 2.3 (Feature selection)\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.814217600672198, colsample_bytree=1.0, eval_metric=mlogloss, gamma=5.310624388727857e-09, learning_rate=0.001, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=314, objective=multi:softmax, reg_alpha=0.22944898295705243, reg_lambda=2.9806442789202032e-06, subsample=0.6683284989913967;, score=0.773 total time= 6.5min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=auc, gamma=0.0005616318866234174, learning_rate=0.047560616156956864, max_delta_step=10, max_depth=7, min_child_weight=2, n_estimators=233, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0;, score=0.775 total time=   2.1s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.814217600672198, colsample_bytree=1.0, eval_metric=mlogloss, gamma=5.310624388727857e-09, learning_rate=0.001, max_delta_step=9, max_depth=15, min_child_weight=7, n_estimators=314, objective=multi:softmax, reg_alpha=0.22944898295705243, reg_lambda=2.9806442789202032e-06, subsample=0.6683284989913967;, score=0.772 total time= 6.5min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=1.0, colsample_bytree=0.5, eval_metric=auc, gamma=0.0005616318866234174, learning_rate=0.047560616156956864, max_delta_step=10, max_depth=7, min_child_weight=2, n_estimators=233, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=1e-09, subsample=1.0;, score=0.775 total time=   2.0s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6117405740041535, colsample_bytree=0.642533688222915, eval_metric=auc, gamma=3.1835603621905298e-06, learning_rate=0.01297018298138197, max_delta_step=10, max_depth=3, min_child_weight=4, n_estimators=310, objective=multi:softmax, reg_alpha=1.5043295429234514e-08, reg_lambda=0.6578416666859456, subsample=0.577394060504311;, score=0.766 total time=   0.8s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6117405740041535, colsample_bytree=0.642533688222915, eval_metric=auc, gamma=3.1835603621905298e-06, learning_rate=0.01297018298138197, max_delta_step=10, max_depth=3, min_child_weight=4, n_estimators=310, objective=multi:softmax, reg_alpha=1.5043295429234514e-08, reg_lambda=0.6578416666859456, subsample=0.577394060504311;, score=0.766 total time=   0.8s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=1.0, eval_metric=auc, gamma=4.999999999999999, learning_rate=0.001, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=1e-09, subsample=1.0;, score=0.767 total time=   2.2s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=1.0, eval_metric=auc, gamma=4.999999999999999, learning_rate=0.001, max_delta_step=10, max_depth=15, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=1e-09, subsample=1.0;, score=0.765 total time=   2.3s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6589426098300931, colsample_bytree=1.0, eval_metric=auc, gamma=0.00031048475683596963, learning_rate=0.02306310728186984, max_delta_step=10, max_depth=11, min_child_weight=7, n_estimators=500, objective=multi:softmax, reg_alpha=0.00838983350312091, reg_lambda=2.436342204298964e-08, subsample=0.5;, score=0.773 total time=   5.9s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6589426098300931, colsample_bytree=1.0, eval_metric=auc, gamma=0.00031048475683596963, learning_rate=0.02306310728186984, max_delta_step=10, max_depth=11, min_child_weight=7, n_estimators=500, objective=multi:softmax, reg_alpha=0.00838983350312091, reg_lambda=2.436342204298964e-08, subsample=0.5;, score=0.776 total time=   6.1s\n",
      "STEP 2.4 (HyperParameter Tuning Part 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.771 total time=   4.2s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.771 total time=   4.2s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.773 total time=   5.6s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.774 total time=   5.7s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.757 total time=   1.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.760 total time=   1.1s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.774 total time= 4.5min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.769 total time= 4.5min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 3.0min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.769 total time=   2.1s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.753 total time= 3.0min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.764 total time=   2.0s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.775 total time=   1.8s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.743 total time= 5.2min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.763 total time=   2.5s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.775 total time=   1.7s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5773526958044634, colsample_bytree=0.6245201554591239, eval_metric=error, gamma=0.00022102122605029267, learning_rate=0.9928700613948309, max_delta_step=7, max_depth=8, min_child_weight=9, n_estimators=412, objective=multi:softmax, reg_alpha=0.10652083671810603, reg_lambda=9.905585783505449e-06, subsample=0.6202791503650118;, score=0.741 total time= 5.2min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6080155350117447, colsample_bytree=0.5198450538508611, eval_metric=error, gamma=1.0766429149689044e-08, learning_rate=0.30823030676040875, max_delta_step=2, max_depth=9, min_child_weight=7, n_estimators=305, objective=multi:softmax, reg_alpha=1.223617668145378, reg_lambda=7.89241793471874e-09, subsample=0.5761888064729442;, score=0.763 total time=   1.3s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.770 total time=   1.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5159744566516128, colsample_bytree=0.9475733277011458, eval_metric=auc, gamma=0.003403463514866047, learning_rate=0.00117973526902535, max_delta_step=9, max_depth=5, min_child_weight=4, n_estimators=449, objective=multi:softmax, reg_alpha=0.00048334966339732264, reg_lambda=1.8451449961184172e-07, subsample=0.8915860268715323;, score=0.769 total time=   1.6s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8799902826333548, colsample_bytree=0.9550877329000345, eval_metric=auc, gamma=4.278410229117492e-09, learning_rate=0.02167478520437157, max_delta_step=0, max_depth=5, min_child_weight=3, n_estimators=458, objective=multi:softmax, reg_alpha=6.474978389720245e-05, reg_lambda=0.00014746092664602448, subsample=0.6107374133883687;, score=0.778 total time=   1.8s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8799902826333548, colsample_bytree=0.9550877329000345, eval_metric=auc, gamma=4.278410229117492e-09, learning_rate=0.02167478520437157, max_delta_step=0, max_depth=5, min_child_weight=3, n_estimators=458, objective=multi:softmax, reg_alpha=6.474978389720245e-05, reg_lambda=0.00014746092664602448, subsample=0.6107374133883687;, score=0.776 total time=   1.9s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9373114874927626, colsample_bytree=0.9569253632716257, eval_metric=auc, gamma=0.0016918356235953664, learning_rate=1.0, max_delta_step=6, max_depth=14, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=1.137714091845722, reg_lambda=0.00016989192129933137, subsample=1.0;, score=0.757 total time=   0.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9373114874927626, colsample_bytree=0.9569253632716257, eval_metric=auc, gamma=0.0016918356235953664, learning_rate=1.0, max_delta_step=6, max_depth=14, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=1.137714091845722, reg_lambda=0.00016989192129933137, subsample=1.0;, score=0.759 total time=   0.4s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, eval_metric=auc, gamma=1e-09, learning_rate=1.0, max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5;, score=0.759 total time=   0.8s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5, colsample_bytree=0.5, eval_metric=auc, gamma=1e-09, learning_rate=1.0, max_delta_step=0, max_depth=3, min_child_weight=1, n_estimators=500, objective=multi:softmax, reg_alpha=10.0, reg_lambda=10.0, subsample=0.5;, score=0.758 total time=   0.8s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.834391421184981, colsample_bytree=0.8080923048255151, eval_metric=auc, gamma=1.4398486042759043e-09, learning_rate=0.001, max_delta_step=10, max_depth=12, min_child_weight=4, n_estimators=237, objective=multi:softmax, reg_alpha=2.9997259806667775e-07, reg_lambda=8.759114895916142, subsample=0.9469931227915911;, score=0.772 total time= 1.9min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.877097174559598, colsample_bytree=0.7729220956258913, eval_metric=error, gamma=7.834998350203914e-06, learning_rate=0.0385996426389019, max_delta_step=5, max_depth=9, min_child_weight=5, n_estimators=352, objective=multi:softmax, reg_alpha=0.38227494284553437, reg_lambda=1e-09, subsample=0.5264193191195917;, score=0.775 total time= 4.1min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.834391421184981, colsample_bytree=0.8080923048255151, eval_metric=auc, gamma=1.4398486042759043e-09, learning_rate=0.001, max_delta_step=10, max_depth=12, min_child_weight=4, n_estimators=237, objective=multi:softmax, reg_alpha=2.9997259806667775e-07, reg_lambda=8.759114895916142, subsample=0.9469931227915911;, score=0.774 total time= 1.9min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.877097174559598, colsample_bytree=0.7729220956258913, eval_metric=error, gamma=7.834998350203914e-06, learning_rate=0.0385996426389019, max_delta_step=5, max_depth=9, min_child_weight=5, n_estimators=352, objective=multi:softmax, reg_alpha=0.38227494284553437, reg_lambda=1e-09, subsample=0.5264193191195917;, score=0.776 total time= 4.0min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9927167883026082, colsample_bytree=0.6940220075604079, eval_metric=auc, gamma=0.0016586332244427698, learning_rate=0.011641760236051922, max_delta_step=2, max_depth=14, min_child_weight=7, n_estimators=380, objective=multi:softmax, reg_alpha=2.3248060232666703e-09, reg_lambda=10.0, subsample=0.6750174382943398;, score=0.777 total time= 4.8min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.907500670305764, colsample_bytree=0.5, eval_metric=mlogloss, gamma=4.999999999999999, learning_rate=0.03711559265067431, max_delta_step=0, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=1.6391169574366082, reg_lambda=0.08208647677131987, subsample=0.5;, score=0.756 total time=   4.3s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9927167883026082, colsample_bytree=0.6940220075604079, eval_metric=auc, gamma=0.0016586332244427698, learning_rate=0.011641760236051922, max_delta_step=2, max_depth=14, min_child_weight=7, n_estimators=380, objective=multi:softmax, reg_alpha=2.3248060232666703e-09, reg_lambda=10.0, subsample=0.6750174382943398;, score=0.779 total time= 4.8min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.907500670305764, colsample_bytree=0.5, eval_metric=mlogloss, gamma=4.999999999999999, learning_rate=0.03711559265067431, max_delta_step=0, max_depth=15, min_child_weight=10, n_estimators=50, objective=multi:softmax, reg_alpha=1.6391169574366082, reg_lambda=0.08208647677131987, subsample=0.5;, score=0.755 total time=   5.2s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.910999103788712, colsample_bytree=0.8103044506997967, eval_metric=auc, gamma=1.283365756685285e-09, learning_rate=0.03281695250574116, max_delta_step=0, max_depth=7, min_child_weight=4, n_estimators=50, objective=multi:softmax, reg_alpha=1.3003217658870463e-06, reg_lambda=0.00025575962116971065, subsample=0.6290667037861472;, score=0.775 total time=   4.9s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.910999103788712, colsample_bytree=0.8103044506997967, eval_metric=auc, gamma=1.283365756685285e-09, learning_rate=0.03281695250574116, max_delta_step=0, max_depth=7, min_child_weight=4, n_estimators=50, objective=multi:softmax, reg_alpha=1.3003217658870463e-06, reg_lambda=0.00025575962116971065, subsample=0.6290667037861472;, score=0.772 total time=   4.9s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6629389644299019, colsample_bytree=0.5025602631620186, eval_metric=auc, gamma=0.001192196456790764, learning_rate=0.001, max_delta_step=0, max_depth=12, min_child_weight=9, n_estimators=50, objective=multi:softmax, reg_alpha=0.037487239940307206, reg_lambda=0.0006876808369259808, subsample=0.6278163028571189;, score=0.764 total time=   5.5s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6629389644299019, colsample_bytree=0.5025602631620186, eval_metric=auc, gamma=0.001192196456790764, learning_rate=0.001, max_delta_step=0, max_depth=12, min_child_weight=9, n_estimators=50, objective=multi:softmax, reg_alpha=0.037487239940307206, reg_lambda=0.0006876808369259808, subsample=0.6278163028571189;, score=0.759 total time=   5.6s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9659523267727381, colsample_bytree=0.7562741462278328, eval_metric=auc, gamma=3.2262456055466855e-07, learning_rate=0.011137008608389957, max_delta_step=6, max_depth=13, min_child_weight=10, n_estimators=500, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=10.0, subsample=1.0;, score=0.778 total time= 8.4min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8486174131671578, colsample_bytree=0.6848877527254154, eval_metric=error, gamma=2.2782406693088234e-07, learning_rate=0.01490155911849774, max_delta_step=10, max_depth=8, min_child_weight=6, n_estimators=318, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=8.125554085344959, subsample=0.7766427563782428;, score=0.776 total time=   2.5s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9659523267727381, colsample_bytree=0.7562741462278328, eval_metric=auc, gamma=3.2262456055466855e-07, learning_rate=0.011137008608389957, max_delta_step=6, max_depth=13, min_child_weight=10, n_estimators=500, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=10.0, subsample=1.0;, score=0.779 total time= 8.4min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8486174131671578, colsample_bytree=0.6848877527254154, eval_metric=error, gamma=2.2782406693088234e-07, learning_rate=0.01490155911849774, max_delta_step=10, max_depth=8, min_child_weight=6, n_estimators=318, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=8.125554085344959, subsample=0.7766427563782428;, score=0.776 total time=   2.3s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9982477412245345, colsample_bytree=1.0, eval_metric=mlogloss, gamma=4.235743017914968, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=8, n_estimators=301, objective=multi:softmax, reg_alpha=1.6359742898436345e-09, reg_lambda=5.5570123216107445, subsample=0.8351906785368748;, score=0.770 total time= 2.5min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9982477412245345, colsample_bytree=1.0, eval_metric=mlogloss, gamma=4.235743017914968, learning_rate=1.0, max_delta_step=10, max_depth=8, min_child_weight=8, n_estimators=301, objective=multi:softmax, reg_alpha=1.6359742898436345e-09, reg_lambda=5.5570123216107445, subsample=0.8351906785368748;, score=0.771 total time= 2.5min\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "STEP 3 (Prediction)\n",
      "Fold #3\n",
      "STEP 1 (Splitting)\n",
      "STEP 2 (Tuning)\n",
      "STEP 2.1 (HyperParameter Tuning Part 1)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.9548205945943856, colsample_bytree=0.8064040974284664, eval_metric=error, gamma=0.0002599890889531601, learning_rate=0.0032306368681315457, max_delta_step=5, max_depth=14, min_child_weight=9, n_estimators=330, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=2.5064929030774825e-07, subsample=0.7198842108293311;, score=0.775 total time= 3.9min\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.5018226020355286, colsample_bytree=0.5, eval_metric=auc, gamma=1.6513140541813376e-09, learning_rate=0.038075072061383865, max_delta_step=0, max_depth=11, min_child_weight=4, n_estimators=500, objective=multi:softmax, reg_alpha=1.181201383209066, reg_lambda=10.0, subsample=0.7056448841711012;, score=0.775 total time= 8.3min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8042241718864502, colsample_bytree=1.0, eval_metric=error, gamma=6.148264851060223e-07, learning_rate=0.047900532599885644, max_delta_step=4, max_depth=14, min_child_weight=3, n_estimators=371, objective=multi:softmax, reg_alpha=10.0, reg_lambda=2.928518997208908e-06, subsample=1.0;, score=0.780 total time=   4.3s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.9548205945943856, colsample_bytree=0.8064040974284664, eval_metric=error, gamma=0.0002599890889531601, learning_rate=0.0032306368681315457, max_delta_step=5, max_depth=14, min_child_weight=9, n_estimators=330, objective=multi:softmax, reg_alpha=1e-09, reg_lambda=2.5064929030774825e-07, subsample=0.7198842108293311;, score=0.774 total time= 4.0min\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.5018226020355286, colsample_bytree=0.5, eval_metric=auc, gamma=1.6513140541813376e-09, learning_rate=0.038075072061383865, max_delta_step=0, max_depth=11, min_child_weight=4, n_estimators=500, objective=multi:softmax, reg_alpha=1.181201383209066, reg_lambda=10.0, subsample=0.7056448841711012;, score=0.776 total time= 8.3min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8042241718864502, colsample_bytree=1.0, eval_metric=error, gamma=6.148264851060223e-07, learning_rate=0.047900532599885644, max_delta_step=4, max_depth=14, min_child_weight=3, n_estimators=371, objective=multi:softmax, reg_alpha=10.0, reg_lambda=2.928518997208908e-06, subsample=1.0;, score=0.774 total time=   3.7s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.754 total time= 5.9min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.769 total time=   3.1s\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6016860454008977, colsample_bytree=0.6914616493449374, eval_metric=mlogloss, gamma=1.1297789612218166e-08, learning_rate=0.001148164544580019, max_delta_step=1, max_depth=3, min_child_weight=2, n_estimators=322, objective=multi:softmax, reg_alpha=0.016962754998657795, reg_lambda=1.7191475662134262e-05, subsample=0.5317514724347071;, score=0.756 total time= 5.9min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5431099842871672, colsample_bytree=0.8042479135573553, eval_metric=auc, gamma=1.560790032675869, learning_rate=0.002039152021358742, max_delta_step=5, max_depth=13, min_child_weight=5, n_estimators=199, objective=multi:softmax, reg_alpha=3.4327014361865584e-07, reg_lambda=0.5355007350922075, subsample=0.9297692293357799;, score=0.772 total time=   3.0s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.769 total time=   6.4s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.5823201338785988, colsample_bytree=0.523144201265553, eval_metric=error, gamma=0.00022753718199864352, learning_rate=0.005379114240624445, max_delta_step=8, max_depth=14, min_child_weight=2, n_estimators=269, objective=multi:softmax, reg_alpha=3.827454954714524, reg_lambda=9.560131563226728e-06, subsample=0.8872030876414851;, score=0.766 total time=   6.9s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.774 total time=   8.9s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.9210992271589409, colsample_bytree=0.9442231147032201, eval_metric=auc, gamma=2.4617834665530035e-06, learning_rate=0.004846107029356892, max_delta_step=6, max_depth=8, min_child_weight=3, n_estimators=418, objective=multi:softmax, reg_alpha=1.552347794916759e-08, reg_lambda=2.6400829005725725e-08, subsample=0.8245725242405524;, score=0.775 total time=   9.1s\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.753 total time=   1.5s\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.8248943714069297, colsample_bytree=0.7093553662303278, eval_metric=mlogloss, gamma=4.6107763546447025e-07, learning_rate=0.742392438370981, max_delta_step=1, max_depth=13, min_child_weight=9, n_estimators=331, objective=multi:softmax, reg_alpha=7.113560430603634e-07, reg_lambda=3.93247619299423e-06, subsample=0.8161872199009836;, score=0.756 total time=   1.5s\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "[CV 1/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.767 total time= 8.2min\n",
      "[CV 1/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.763 total time=   2.8s\n",
      "[CV 2/2] END booster=dart, colsample_bylevel=0.6263362171395246, colsample_bytree=0.5547692538151737, eval_metric=auc, gamma=0.001143548643595771, learning_rate=0.13033209244859392, max_delta_step=4, max_depth=12, min_child_weight=10, n_estimators=367, objective=multi:softmax, reg_alpha=2.702423611151236, reg_lambda=0.9285490375880117, subsample=0.8854246244930968;, score=0.775 total time= 8.3min\n",
      "[CV 2/2] END booster=gbtree, colsample_bylevel=0.6442749093404072, colsample_bytree=0.7735181684591523, eval_metric=mlogloss, gamma=4.746561123982151e-05, learning_rate=0.15614182642885918, max_delta_step=8, max_depth=8, min_child_weight=3, n_estimators=379, objective=multi:softmax, reg_alpha=3.8298622378678744e-07, reg_lambda=0.006995743978086094, subsample=0.5346550310205367;, score=0.768 total time=   3.0s\n"
     ]
    }
   ],
   "source": [
    "results = nested_CV_revenge(\n",
    "    outer_cv, inner_cv,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    model=classifier,\n",
    "    search_space=search_space_bayes,\n",
    "    n_jobs= n_jobs, n_iter_bsearch = n_iter_bsearch,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "(\n",
    "    hyperparam_list,\n",
    "    selected_features_list,\n",
    "    accuracy_array,\n",
    "    f1_array,\n",
    "    precision_array,\n",
    "    recall_array,\n",
    "    roc_auc_array,\n",
    "    predictions_array,\n",
    "    probas_array\n",
    ") = results\n",
    "\n",
    "clear_output(wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The cross-validated accuracy (cv = {outer_cv}) is: {np.mean(accuracy_array)}\")\n",
    "print(f\"The cross-validated f1 (cv = {outer_cv}) is: {np.mean(f1_array)}\")\n",
    "print(f\"The cross-validated precision (cv = {outer_cv}) is: {np.mean(precision_array)}\")\n",
    "print(f\"The cross-validated recall (cv = {outer_cv}) is: {np.mean(recall_array)}\")\n",
    "print(f\"The cross-validated AUC (cv = {outer_cv}) is: {np.mean(roc_auc_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_in_at_least_one_cv = set([elem for inner_list in selected_features_list for elem in inner_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space_grid = {}\n",
    "\n",
    "for dictionary in hyperparam_list:\n",
    "    for k,v in dictionary.items():\n",
    "        if k in search_space_grid:\n",
    "            search_space_grid[k].update([v])\n",
    "        else:\n",
    "            search_space_grid[k] = set([v])\n",
    "\n",
    "search_space_grid = {k : list(v) for k,v in search_space_grid.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Dataset Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti = sk.model_selection.RandomizedSearchCV(estimator = classifier, \n",
    "                                             param_distributions = search_space_grid, \n",
    "                                             cv = inner_cv, \n",
    "                                             n_jobs = n_jobs,\n",
    "                                             n_iter = n_iter_rsearch,\n",
    "                                             random_state = hypertune_random_state_rsearch, \n",
    "                                             verbose = 0, refit = True)\n",
    "opti.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = opti.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at both XGBoost native feature importance and at mean absolute SHAP values as metric of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "shap_values_numpy = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_shap:\n",
    "    print(\" / \".join([mode, condition]))\n",
    "    plt.figure(figsize = (100,25))\n",
    "    summary_plot = shap.summary_plot(shap_values, X_train, \n",
    "                                     plot_type='bar', max_display=10, plot_size= (25,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform Feature Selection using mean absolute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = model.feature_names_in_\n",
    "feature_importances_shap = np.mean(np.mean(np.abs(explainer.shap_values(X_train)), axis = 0),axis = 1)\n",
    "\n",
    "X_train_reduced, X_test_reduced, selected_features = feature_selector_shap(feature_names, feature_importances_shap, \n",
    "                                                                            model, X_train, X_test, y_train, \n",
    "                                                                            inner_cv = inner_cv,\n",
    "                                                                            plot = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_discard = [feature for feature in selected_features if feature not in selected_features_in_at_least_one_cv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dropping columns never selected during Nested Cross Validation: {features_to_discard}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = X_train_reduced.drop(features_to_discard, axis = 1)\n",
    "X_test_reduced = X_test_reduced.drop(features_to_discard, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_fs = sk.model_selection.RandomizedSearchCV(estimator = model, \n",
    "                                                param_distributions = search_space_grid, \n",
    "                                                cv = inner_cv, \n",
    "                                                n_jobs = n_jobs,\n",
    "                                                n_iter = n_iter_rsearch,\n",
    "                                                random_state = hypertune_random_state_rsearch, \n",
    "                                                verbose = 0, refit = True)\n",
    "opti_fs.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fs = opti_fs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_fs = opti_fs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in best_params_fs.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = sk.metrics.make_scorer(sk.metrics.f1_score, average=\"macro\")\n",
    "precision_macro = sk.metrics.make_scorer(sk.metrics.precision_score, average=\"macro\")\n",
    "recall_macro = sk.metrics.make_scorer(sk.metrics.recall_score, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array_fs = np.mean(sk.model_selection.cross_val_score(model_fs, X_train_reduced, y_train, cv = outer_cv, scoring = \"accuracy\"))\n",
    "f1_array_fs = np.mean(sk.model_selection.cross_val_score(model_fs, X_train_reduced, y_train, cv = outer_cv, scoring = f1_macro))\n",
    "precision_array_fs = np.mean(sk.model_selection.cross_val_score(model_fs, X_train_reduced, y_train, cv = outer_cv, scoring = precision_macro))\n",
    "recall_array_fs = np.mean(sk.model_selection.cross_val_score(model_fs, X_train_reduced, y_train, cv = outer_cv, scoring = recall_macro))\n",
    "roc_auc_array_fs = np.mean(sk.model_selection.cross_val_score(model_fs, X_train_reduced, y_train, cv = outer_cv, scoring = \"roc_auc_ovr\"))\n",
    "\n",
    "proba_predictions_fs = sk.model_selection.cross_val_predict(model_fs, X_train_reduced, y_train, cv = outer_cv, method= \"predict_proba\")\n",
    "class_array_fs = sk.model_selection.cross_val_predict(model_fs, X_train_reduced, y_train, cv = outer_cv, method= \"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = sk.preprocessing.LabelBinarizer().fit(y_train)\n",
    "y_onehot_train = label_binarizer.transform(y_train)\n",
    "n_classes = y_onehot_train.shape[1]\n",
    "target_names = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = sk.metrics.roc_curve(y_onehot_train[:, i], proba_predictions_fs[:, i])\n",
    "    roc_auc[i] = sk.metrics.auc(fpr[i], tpr[i])\n",
    "\n",
    "fpr_grid = np.linspace(0.0, 1.0, 1000)\n",
    "\n",
    "mean_tpr = np.zeros_like(fpr_grid)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(fpr_grid, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = fpr_grid\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = sk.metrics.auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "print(f\"Macro-averaged One-vs-Rest ROC AUC score: {roc_auc['macro']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=f\"macro-average ROC curve (AUC = {roc_auc['macro']:.2f})\",\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    sk.metrics.RocCurveDisplay.from_predictions(\n",
    "        y_onehot_train[:, class_id],\n",
    "        proba_predictions_fs[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        plot_chance_level=(class_id == 2),\n",
    "        despine=True,\n",
    "    )\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Variables for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X_train_reduced,open(X_train_filename,\"wb\"))\n",
    "pickle.dump(X_test_reduced,open(X_test_filename,\"wb\"))\n",
    "pickle.dump(y_train,open(y_train_filename,\"wb\"))\n",
    "pickle.dump(y_test,open(y_test_filename,\"wb\"))\n",
    "pickle.dump(bin_train,open(bin_train_filename,\"wb\"))\n",
    "pickle.dump(bin_test,open(bin_test_filename,\"wb\"))\n",
    "pickle.dump(model_fs,open(model_filename,\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (System)",
   "language": "python",
   "name": "python3-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
